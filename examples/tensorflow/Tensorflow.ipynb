{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.tfrecord as tfrec\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "base = \"/data/imagenet/train-val-recordio-256/\"\n",
    "idx_files = [base + \"val.idx\"]\n",
    "rec_files = [base + \"val.rec\"]\n",
    "idx_files\n",
    "\n",
    "BURNIN_STEPS = 6\n",
    "BATCH_SIZE = 128\n",
    "DEVICES = 2\n",
    "ITERATIONS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPipe(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id, num_gpus):\n",
    "        super(HybridPipe, self).__init__(batch_size,\n",
    "                                         num_threads,\n",
    "                                         device_id)\n",
    "        self.input = ops.MXNetReader(path = rec_files, index_path = idx_files, shard_id = 0, num_shards = 1)\n",
    "\n",
    "        self.decode = ops.nvJPEGDecoder(device = \"mixed\", output_type = types.RGB)\n",
    "        self.resize = ops.Resize(device = \"gpu\", random_resize = True,\n",
    "                                 resize_a = 256, resize_b = 480,\n",
    "                                 image_type = types.RGB,\n",
    "                                 interp_type = types.INTERP_LINEAR)\n",
    "        self.cmn = ops.CropMirrorNormalize(device = \"gpu\",\n",
    "                                            output_dtype = types.FLOAT,\n",
    "                                            crop = (224, 224),\n",
    "                                            image_type = types.RGB,\n",
    "                                            mean = [128., 128., 128.],\n",
    "                                            std = [1., 1., 1.])\n",
    "        self.uniform = ops.Uniform(range = (0.0, 1.0))\n",
    "        self.iter = 0\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.input(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        images = self.resize(images)\n",
    "        output = self.cmn(images, crop_pos_x = self.uniform(),\n",
    "                          crop_pos_y = self.uniform())\n",
    "        return (output, labels.gpu())\n",
    "\n",
    "    def iter_setup(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [HybridPipe(batch_size=BATCH_SIZE, num_threads=2, device_id = device_id, num_gpus = 1) for device_id in range(DEVICES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_pipes = [pipe.serialize() for pipe in pipes]\n",
    "del pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import nvidia.dali.plugin.tf as dali_tf\n",
    "import time\n",
    "daliop = dali_tf.DALIIterator()\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for d in range(DEVICES):\n",
    "    print(\"DALIOP with device %i\" % d)\n",
    "    with tf.device('/gpu:%i' % d):\n",
    "        image, label = daliop(serialized_pipeline = serialized_pipes[d],\n",
    "            batch_size = BATCH_SIZE,\n",
    "            height = 224,\n",
    "            width = 224,\n",
    "            device_id = d)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    print(\"in session\")\n",
    "    all_img_per_sec = []\n",
    "    total_batch_size = BATCH_SIZE * DEVICES\n",
    "    \n",
    "    for i in range(ITERATIONS):\n",
    "        start_time = time.time()\n",
    "        res = sess.run([images, labels])\n",
    "        elapsed_time = time.time() - start_time\n",
    "        img_per_sec = total_batch_size / elapsed_time\n",
    "        if i > BURNIN_STEPS:\n",
    "            all_img_per_sec.append(img_per_sec)\n",
    "        print(\"\\t%7.1f img/s\" %  img_per_sec)\n",
    "\n",
    "    print(\"TOTAL AVG %7.1f img/s\" % (sum(all_img_per_sec) / len(all_img_per_sec)))\n",
    "    print(res[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(res[0][0].shape)\n",
    "img = res[0][0][10].transpose() + 128\n",
    "imgplot = plt.imshow(img.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ndll.plugin.tf as ndll_tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import data_flow_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "\n",
    "from ndll.pipeline import Pipeline\n",
    "import ndll.ops as ops\n",
    "import ndll.types as types\n",
    "import ndll.tfrecord as tfrec\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tensorflow.contrib import nccl\n",
    "    have_nccl = True\n",
    "except ImportError:\n",
    "    have_nccl = False\n",
    "    print(\"WARNING: NCCL support not available\")\n",
    "\n",
    "__version__ = \"1.4\"\n",
    "\n",
    "base = \"/data/imagenet/train-val-recordio-256/\"\n",
    "#base = '/opt/ndll/examples/recordio/'\n",
    "idx_files = [base + \"val.idx\"]\n",
    "rec_files = [base + \"val.rec\"]\n",
    "idx_files\n",
    "\n",
    "TFRECORD_DIR = \"/data/imagenet/train-val-tfrecord-480-subset/\"\n",
    "#TFRECORD_DIR = \"/opt/ndll/examples/train-val-tfrecord-480-subset/\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICES = 1\n",
    "NRECORDS = sum(1 for line in open(idx_files[0]))\n",
    "NRECORDS\n",
    "\n",
    "NDLL_ON = True\n",
    "\n",
    "model_dtype = tf.float32 # or tf.float32\n",
    "nlayer = 50\n",
    "nclass = 1000\n",
    "\n",
    "total_batch_size = BATCH_SIZE * DEVICES\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "momentum = 0.9\n",
    "lr_decay_policy = 'step'\n",
    "lr_decay_epochs = 30\n",
    "lr_decay_rate = 0.1\n",
    "loss_scale = 1\n",
    "nccl_on = False\n",
    "nstep_burnin = 20\n",
    "display_every = 1\n",
    "input_buffer_size = min(10000, NRECORDS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet[nlayer] model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyScope(object):\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "\n",
    "\n",
    "def resnet_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride,\n",
    "                         basic=False):\n",
    "    num_inputs = input_layer.get_shape().as_list()[1]\n",
    "    x = input_layer\n",
    "    s = stride\n",
    "    with tf.name_scope('resnet_v1'):\n",
    "        if depth == num_inputs:\n",
    "            if stride == 1:\n",
    "                shortcut = input_layer\n",
    "            else:\n",
    "                shortcut = net.pool(x, 'MAX', (1,1), (s,s))\n",
    "        else:\n",
    "            shortcut = net.conv(x, depth, (1,1), (s,s), activation='LINEAR')\n",
    "        if basic:\n",
    "            x = net.conv(x, depth_bottleneck, (3,3), (s,s), padding='SAME_RESNET')\n",
    "            x = net.conv(x, depth,            (3,3), activation='LINEAR')\n",
    "        else:\n",
    "            x = net.conv(x, depth_bottleneck, (1,1), (s,s))\n",
    "            x = net.conv(x, depth_bottleneck, (3,3), padding='SAME')\n",
    "            x = net.conv(x, depth,            (1,1), activation='LINEAR')\n",
    "        with net.jit_scope():\n",
    "            x = net.activate(x + shortcut)\n",
    "        return x\n",
    "\n",
    "def resnext_split_branch(net, input_layer, stride):\n",
    "    x = input_layer\n",
    "    with tf.name_scope('resnext_split_branch'):\n",
    "        x = net.conv(x, net.bottleneck_width, (1, 1), (stride, stride), activation='RELU', use_batch_norm=True)\n",
    "        x = net.conv(x, net.bottleneck_width, (3, 3), (1, 1), activation='RELU', use_batch_norm=True)\n",
    "    return x\n",
    "\n",
    "def resnext_shortcut(net, input_layer, stride, input_size, output_size):\n",
    "    x = input_layer\n",
    "    useConv = net.shortcut_type == 'C' or (net.shortcut_type == 'B' and input_size != output_size)\n",
    "    with tf.name_scope('resnext_shortcut'):\n",
    "        if useConv:\n",
    "            x = net.conv(x, output_size, (1,1), (stride, stride), use_batch_norm=True)\n",
    "        elif output_size == input_size:\n",
    "            if stride == 1:\n",
    "                x = input_layer\n",
    "            else:\n",
    "                x = net.pool(x, 'MAX', (1,1), (stride, stride))\n",
    "        else:\n",
    "            x = input_layer\n",
    "    return x\n",
    "\n",
    "def resnext_bottleneck_v1(net, input_layer, depth, depth_bottleneck, stride):\n",
    "    num_inputs = input_layer.get_shape().as_list()[1]\n",
    "    x = input_layer\n",
    "    with tf.name_scope('resnext_bottleneck_v1'):\n",
    "        shortcut = resnext_shortcut(net, x, stride, num_inputs, depth)\n",
    "        branches_list = []\n",
    "        for i in range(net.cardinality):\n",
    "            branch = resnext_split_branch(net, x, stride)\n",
    "            branches_list.append(branch)\n",
    "        concatenated_branches = tf.concat(values=branches_list, axis=1, name='concat')\n",
    "        bottleneck_depth = concatenated_branches.get_shape().as_list()[1]\n",
    "        x = net.conv(concatenated_branches, depth, (1, 1), (1, 1), activation=None)\n",
    "        x = net.activate(x + shortcut, 'RELU')\n",
    "    return x\n",
    "\n",
    "def inference_residual(net, input_layer, layer_counts, bottleneck_callback):\n",
    "    net.use_batch_norm = True\n",
    "    x = net.input_layer(input_layer)\n",
    "    x = net.conv(x, 64,    (7,7), (2,2), padding='SAME_RESNET')\n",
    "    x = net.pool(x, 'MAX', (3,3), (2,2), padding='SAME')\n",
    "    for i in range(layer_counts[0]):\n",
    "        x = bottleneck_callback(net, x,  256,  64, 1)\n",
    "    for i in range(layer_counts[1]):\n",
    "        x = bottleneck_callback(net, x, 512, 128, 2 if i==0 else 1)\n",
    "    for i in range(layer_counts[2]):\n",
    "        x = bottleneck_callback(net, x, 1024, 256, 2 if i==0 else 1)\n",
    "    for i in range(layer_counts[3]):\n",
    "        x = bottleneck_callback(net, x, 2048, 512, 2 if i==0 else 1)\n",
    "    x = net.spatial_avg(x)\n",
    "    return x\n",
    "\n",
    "def inference_resnet_v1_impl(net, input_layer, layer_counts):\n",
    "    return inference_residual(net, input_layer, layer_counts, resnet_bottleneck_v1)\n",
    "\n",
    "def inference_resnet_v1(net, input_layer, nlayer):\n",
    "    \"\"\"Deep Residual Networks family of models\n",
    "    https://arxiv.org/abs/1512.03385\n",
    "    \"\"\"\n",
    "    if nlayer ==  50: return inference_resnet_v1_impl(net, input_layer, [3,4, 6,3])\n",
    "    elif nlayer == 152: return inference_resnet_v1_impl(net, input_layer, [3,8,36,3])\n",
    "    else: raise ValueError(\"Invalid nlayer (%i); must be one of: 50,152\" % nlayer)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUNetworkBuilder(object):\n",
    "    \"\"\"This class provides convenient methods for constructing feed-forward\n",
    "    networks with internal data layout of 'NCHW'.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 is_training,\n",
    "                 dtype=tf.float32,\n",
    "                 activation='RELU',\n",
    "                 use_batch_norm=True,\n",
    "                 batch_norm_config = {'decay':   0.9,\n",
    "                                      'epsilon': 1e-4,\n",
    "                                      'scale':   True,\n",
    "                                      'zero_debias_moving_mean': False}):\n",
    "        self.dtype             = dtype\n",
    "        self.activation_func   = activation\n",
    "        self.is_training       = is_training\n",
    "        self.use_batch_norm    = use_batch_norm\n",
    "        self.batch_norm_config = batch_norm_config\n",
    "        self._layer_counts     = defaultdict(lambda: 0)\n",
    "        self.jit_scope = DummyScope\n",
    "\n",
    "    def _count_layer(self, layer_type):\n",
    "        idx  = self._layer_counts[layer_type]\n",
    "        name = layer_type + str(idx)\n",
    "        self._layer_counts[layer_type] += 1\n",
    "        return name\n",
    "    def _get_variable(self, name, shape, dtype=None,\n",
    "                      initializer=None, seed=None):\n",
    "        if dtype is None:\n",
    "            dtype = self.dtype\n",
    "        if initializer is None:\n",
    "            initializer = init_ops.glorot_uniform_initializer(seed=seed)\n",
    "        elif (isinstance(initializer, float) or\n",
    "              isinstance(initializer, int)):\n",
    "            initializer = tf.constant_initializer(float(initializer))\n",
    "        return tf.get_variable(name, shape, dtype, initializer)\n",
    "    def _to_nhwc(self, x):\n",
    "        return tf.transpose(x, [0,2,3,1])\n",
    "    def _from_nhwc(self, x):\n",
    "        return tf.transpose(x, [0,3,1,2])\n",
    "    def _bias(self, input_layer):\n",
    "        num_outputs = input_layer.get_shape().as_list()[1]\n",
    "        biases = self._get_variable('biases', [num_outputs], input_layer.dtype,\n",
    "                                    initializer=0)\n",
    "        if len(input_layer.get_shape()) == 4:\n",
    "            return tf.nn.bias_add(input_layer, biases,\n",
    "                                  data_format='NCHW')\n",
    "        else:\n",
    "            return input_layer + biases\n",
    "    def _batch_norm(self, input_layer, scope):\n",
    "        return tf.contrib.layers.batch_norm(input_layer,\n",
    "                                            is_training=self.is_training,\n",
    "                                            scope=scope,\n",
    "                                            data_format='NCHW',\n",
    "                                            fused=True,\n",
    "                                            **self.batch_norm_config)\n",
    "    def _bias_or_batch_norm(self, input_layer, scope, use_batch_norm):\n",
    "        if use_batch_norm is None:\n",
    "            use_batch_norm = self.use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            return self._batch_norm(input_layer, scope)\n",
    "        else:\n",
    "            return self._bias(input_layer)\n",
    "    def input_layer(self, input_layer):\n",
    "        \"\"\"Converts input data into the internal format\"\"\"\n",
    "        with self.jit_scope():\n",
    "            # for ndll\n",
    "            x = self._from_nhwc(input_layer)\n",
    "            #x = input_layer\n",
    "            x = tf.cast(x, self.dtype)\n",
    "            # Rescale and shift to [-1,1]\n",
    "            x = x * (1./127.5) - 1\n",
    "        #print(\"input layer\")\n",
    "        #print(x.get_shape())\n",
    "        return x\n",
    "    def conv(self, input_layer, num_filters, filter_size,\n",
    "             filter_strides=(1,1), padding='SAME',\n",
    "             activation=None, use_batch_norm=None):\n",
    "        \"\"\"Applies a 2D convolution layer that includes bias or batch-norm\n",
    "        and an activation function.\n",
    "        \"\"\"\n",
    "        num_inputs = input_layer.get_shape().as_list()[1]\n",
    "        kernel_shape = [filter_size[0], filter_size[1],\n",
    "                        num_inputs, num_filters]\n",
    "        strides = [1, 1, filter_strides[0], filter_strides[1]]\n",
    "        with tf.variable_scope(self._count_layer('conv')) as scope:\n",
    "            kernel = self._get_variable('weights', kernel_shape,\n",
    "                                        input_layer.dtype)\n",
    "            if padding == 'SAME_RESNET': # ResNet models require custom padding\n",
    "                kh, kw = filter_size\n",
    "                rate = 1\n",
    "                kernel_size_effective = kh + (kw - 1) * (rate - 1)\n",
    "                pad_total = kernel_size_effective - 1\n",
    "                pad_beg = pad_total // 2\n",
    "                pad_end = pad_total - pad_beg\n",
    "                padding = [[0, 0], [0, 0],\n",
    "                           [pad_beg, pad_end], [pad_beg, pad_end]]\n",
    "                input_layer = tf.pad(input_layer, padding)\n",
    "                padding = 'VALID'\n",
    "            x = tf.nn.conv2d(input_layer, kernel, strides,\n",
    "                             padding=padding, data_format='NCHW')\n",
    "            #print(x.get_shape())\n",
    "            x = self._bias_or_batch_norm(x, scope, use_batch_norm)\n",
    "            x = self.activate(x, activation)\n",
    "            return x\n",
    "    def activate(self, input_layer, funcname=None):\n",
    "        \"\"\"Applies an activation function\"\"\"\n",
    "        if isinstance(funcname, tuple):\n",
    "            funcname = funcname[0]\n",
    "            params = funcname[1:]\n",
    "        if funcname is None:\n",
    "            funcname = self.activation_func\n",
    "        if funcname == 'LINEAR':\n",
    "            return input_layer\n",
    "        activation_map = {\n",
    "            'RELU':    tf.nn.relu,\n",
    "            'RELU6':   tf.nn.relu6,\n",
    "            'ELU':     tf.nn.elu,\n",
    "            'SIGMOID': tf.nn.sigmoid,\n",
    "            'TANH':    tf.nn.tanh,\n",
    "            'LRELU':   lambda x, name: tf.maximum(params[0]*x, x, name=name)\n",
    "        }\n",
    "        return activation_map[funcname](input_layer, name=funcname.lower())\n",
    "    def pool(self, input_layer, funcname, window_size,\n",
    "                 window_strides=(2,2),\n",
    "                 padding='VALID'):\n",
    "        \"\"\"Applies spatial pooling\"\"\"\n",
    "        pool_map = {\n",
    "            'MAX': tf.nn.max_pool,\n",
    "            'AVG': tf.nn.avg_pool\n",
    "        }\n",
    "        kernel_size    = [1, 1, window_size[0], window_size[1]]\n",
    "        kernel_strides = [1, 1, window_strides[0], window_strides[1]]\n",
    "        return pool_map[funcname](input_layer, kernel_size, kernel_strides,\n",
    "                                  padding, data_format='NCHW',\n",
    "                                  name=funcname.lower())\n",
    "    def spatial_avg(self, input_layer):\n",
    "        \"\"\"Averages over spatial dimensions (4D->2D)\"\"\"\n",
    "        return tf.reduce_mean(input_layer, [2, 3], name='spatial_avg')\n",
    "    def fully_connected(self, input_layer, num_outputs, activation=None):\n",
    "        \"\"\"Applies a fully-connected set of weights\"\"\"\n",
    "        num_inputs = input_layer.get_shape().as_list()[1]\n",
    "        kernel_size = [num_inputs, num_outputs]\n",
    "        with tf.variable_scope(self._count_layer('fully_connected')):\n",
    "            kernel = self._get_variable('weights', kernel_size,\n",
    "                                        input_layer.dtype)\n",
    "            x = tf.matmul(input_layer, kernel)\n",
    "            x = self._bias(x)\n",
    "            x = self.activate(x, activation)\n",
    "            return x\n",
    "    def residual(self, input_layer, net, scale=1.0, activation='RELU'):\n",
    "        \"\"\"Applies a residual layer\"\"\"\n",
    "        input_size     = input_layer.get_shape().as_list()\n",
    "        num_inputs     = input_size[1]\n",
    "        output_layer   = scale*net(self, input_layer)\n",
    "        output_size    = output_layer.get_shape().as_list()\n",
    "        num_outputs    = output_size[1]\n",
    "        kernel_strides = (input_size[2]//output_size[2],\n",
    "                          input_size[3]//output_size[3])\n",
    "        with tf.name_scope('residual'):\n",
    "            if (num_outputs != num_inputs or\n",
    "                kernel_strides[0] != 1 or\n",
    "                kernel_strides[1] != 1):\n",
    "                input_layer = self.conv(input_layer, num_outputs, [1, 1],\n",
    "                                        kernel_strides, activation='LINEAR')\n",
    "            with self.jit_scope():\n",
    "                x = self.activate(input_layer + output_layer, activation)\n",
    "            return x                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF vanilla image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {\n",
    "        'image/encoded':          tf.FixedLenFeature([ ], tf.string, ''),\n",
    "        'image/class/label':      tf.FixedLenFeature([1], tf.int64,  -1),\n",
    "        'image/class/text':       tf.FixedLenFeature([ ], tf.string, ''),\n",
    "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32)\n",
    "    }\n",
    "    with tf.name_scope('deserialize_image_record'):\n",
    "        obj = tf.parse_single_example(record, feature_map)\n",
    "        imgdata = obj['image/encoded']\n",
    "        label   = tf.cast(obj['image/class/label'], tf.int32)\n",
    "        bbox    = tf.stack([obj['image/object/bbox/%s'%x].values\n",
    "                            for x in ['ymin', 'xmin', 'ymax', 'xmax']])\n",
    "        bbox = tf.transpose(tf.expand_dims(bbox, 0), [0,2,1])\n",
    "        text    = obj['image/class/text']\n",
    "        return imgdata, label, bbox, text\n",
    "\n",
    "def decode_jpeg(imgdata, channels=3):\n",
    "    return tf.image.decode_jpeg(imgdata, channels=channels,\n",
    "                             fancy_upscaling=False,\n",
    "                             dct_method='INTEGER_FAST')\n",
    "\n",
    "def decode_png(imgdata, channels=3):\n",
    "    return tf.image.decode_png(imgdata, channels=channels)\n",
    "\n",
    "def random_crop_and_resize_image(image, bbox, height, width):\n",
    "    with tf.name_scope('random_crop_and_resize'):\n",
    "\n",
    "        bbox_begin, bbox_size, distorted_bbox = tf.image.sample_distorted_bounding_box(\n",
    "            tf.shape(image),\n",
    "            bounding_boxes=bbox,\n",
    "            min_object_covered=0.1,\n",
    "            aspect_ratio_range=[0.8, 1.25],\n",
    "            area_range=[0.1, 1.0],\n",
    "            max_attempts=100,\n",
    "            use_image_if_no_bounding_boxes=True)\n",
    "        # Crop the image to the distorted bounding box\n",
    "        image = tf.slice(image, bbox_begin, bbox_size)\n",
    "        # Resize to the desired output size\n",
    "        image = tf.image.resize_images(\n",
    "            image,\n",
    "            [height, width],\n",
    "            tf.image.ResizeMethod.BILINEAR,\n",
    "            align_corners=False)\n",
    "        image.set_shape([height, width, 3])\n",
    "        return image\n",
    "\n",
    "def stage(tensors):\n",
    "    \"\"\"Stages the given tensors in a StagingArea for asynchronous put/get.\n",
    "    \"\"\"\n",
    "    stage_area = data_flow_ops.StagingArea(\n",
    "     dtypes=[tensor.dtype       for tensor in tensors],\n",
    "     shapes=[tensor.get_shape() for tensor in tensors])\n",
    "    put_op      = stage_area.put(tensors)\n",
    "    get_tensors = stage_area.get()\n",
    "\n",
    "    get_tensors = [tf.reshape(gt, t.get_shape())\n",
    "                for (gt,t) in zip(get_tensors, tensors)]\n",
    "    return put_op, get_tensors\n",
    "\n",
    "\n",
    "class ImagePreprocessor(object):\n",
    "    def __init__(self, height, width, subset='train', dtype=tf.uint8):\n",
    "        self.height = height\n",
    "        self.width  = width\n",
    "        self.num_devices = DEVICES\n",
    "        self.subset = subset\n",
    "        self.dtype = dtype\n",
    "        self.nsummary = 10 # Max no. images to generate summaries for\n",
    "    def preprocess(self, imgdata, bbox, thread_id):\n",
    "        with tf.name_scope('preprocess_image'):\n",
    "            try:\n",
    "                image = decode_jpeg(imgdata)\n",
    "            except:\n",
    "                image = decode_png(imgdata)\n",
    "            if thread_id < self.nsummary:\n",
    "                image_with_bbox = tf.image.draw_bounding_boxes(\n",
    "                    tf.expand_dims(tf.to_float(image), 0), bbox)\n",
    "                tf.summary.image('original_image_and_bbox', image_with_bbox)\n",
    "            image = random_crop_and_resize_image(image, bbox,\n",
    "                                                 self.height, self.width)\n",
    "            if thread_id < self.nsummary:\n",
    "                tf.summary.image('cropped_resized_image',\n",
    "                                 tf.expand_dims(image, 0))\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            if thread_id < self.nsummary:\n",
    "                tf.summary.image('flipped_image',\n",
    "                                 tf.expand_dims(image, 0))\n",
    "        return image\n",
    "    def device_minibatches(self, total_batch_size):\n",
    "        record_input = data_flow_ops.RecordInput(\n",
    "            file_pattern=os.path.join(TFRECORD_DIR, '%s-*' % self.subset),\n",
    "            parallelism=64,\n",
    "            # Note: This causes deadlock during init if larger than dataset preprocess\n",
    "            buffer_size=input_buffer_size,\n",
    "            batch_size=total_batch_size)\n",
    "        records = record_input.get_yield_op()\n",
    "        # Split batch into individual images\n",
    "        records = tf.split(records, total_batch_size, 0)\n",
    "        records = [tf.reshape(record, []) for record in records]\n",
    "        # Deserialize and preprocess images into batches for each device\n",
    "        images = defaultdict(list)\n",
    "        labels = defaultdict(list)\n",
    "        with tf.name_scope('input_pipeline'):\n",
    "            for i, record in enumerate(records):\n",
    "                imgdata, label, bbox, text = deserialize_image_record(record)\n",
    "                image = self.preprocess(imgdata, bbox, thread_id=i)\n",
    "                label -= 1 # Change to 0-based (don't use background class)\n",
    "                device_num = i % self.num_devices\n",
    "                images[device_num].append(image)\n",
    "                labels[device_num].append(label)\n",
    "            # Stack images back into a sub-batch for each device\n",
    "            for device_num in range(self.num_devices):\n",
    "                images[device_num] = tf.parallel_stack(images[device_num])\n",
    "                labels[device_num] = tf.concat(labels[device_num], 0)\n",
    "                images[device_num] = tf.reshape(images[device_num],\n",
    "                                                [-1, self.height, self.width, 3])\n",
    "                images[device_num] = tf.clip_by_value(images[device_num], 0., 255.)\n",
    "                images[device_num] = tf.cast(images[device_num], self.dtype)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALI pipeline preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPipe(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id, num_gpus, pipelined = True, async = True):\n",
    "        super(HybridPipe, self).__init__(batch_size, num_threads, device_id, pipelined, async)\n",
    "        self.input = ops.MXNetReader(path = rec_files, index_path = idx_files, shard_id = device_id, num_shards = num_gpus)\n",
    "\n",
    "        self.huffman = ops.HuffmanDecoder()\n",
    "        self.idct = ops.DCTQuantInv(device = \"gpu\", output_type = types.RGB)\n",
    "        self.resize = ops.Resize(device = \"gpu\", random_resize = True,\n",
    "                                 resize_a = 256, resize_b = 480,\n",
    "                                 image_type = types.RGB,\n",
    "                                 interp_type = types.INTERP_LINEAR)\n",
    "        self.cmn = ops.CropMirrorNormalize(device = \"gpu\",\n",
    "                                            output_dtype = types.FLOAT16,\n",
    "                                            random_crop = True,\n",
    "                                            crop = (224, 224),\n",
    "                                            image_type = types.RGB,\n",
    "                                            mean = [128., 128., 128.],\n",
    "                                            std = [1., 1., 1.],\n",
    "                                            output_layout=types.NHWC)\n",
    "        self.iter = 0\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.input(name=\"Reader\")\n",
    "        dct_coeff, jpeg_meta = self.huffman(inputs)\n",
    "        images = self.idct(dct_coeff.gpu(), jpeg_meta)\n",
    "        images = self.resize(images)\n",
    "        output = self.cmn(images)\n",
    "        return (output, labels.gpu())\n",
    "\n",
    "    def iter_setup(self):\n",
    "        pass\n",
    "\n",
    "class NdllPreprocessor(object):\n",
    "    def __init__(self, height, width, batch_size, dtype=tf.uint8):\n",
    "        self.height = height\n",
    "        self.width  = width\n",
    "        self.batch = batch_size\n",
    "        pipe = HybridPipe(batch_size=self.batch, num_threads=2, device_id = 0, num_gpus = 1, pipelined = True, async = True)\n",
    "        serialized_pipe = pipe.serialize()\n",
    "        del pipe\n",
    "        ndllop = ndll_tf.NDLLIterator()\n",
    "        self.images, self.labels = ndllop(serialized_pipeline = serialized_pipe,\n",
    "                batch_size = batch_size,\n",
    "                height = 224,\n",
    "                width = 224)\n",
    "    def get_device_minibatch(self):\n",
    "        return self.images, self.labels                                                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float32_variable_storage_getter(getter, name, shape=None, dtype=None,\n",
    "                                    initializer=None, regularizer=None,\n",
    "                                    trainable=True,\n",
    "                                    *args, **kwargs):\n",
    "        storage_dtype = tf.float32 if trainable else dtype\n",
    "        variable = getter(name, shape, dtype=storage_dtype,\n",
    "                          initializer=initializer, regularizer=regularizer,\n",
    "                          trainable=trainable,\n",
    "                          *args, **kwargs)\n",
    "        if trainable and dtype != tf.float32:\n",
    "            variable = tf.cast(variable, dtype)\n",
    "        return variable\n",
    "\n",
    "def all_avg_gradients(tower_gradvars, devices, param_server_device='/gpu:0'):\n",
    "    if len(devices) == 1:\n",
    "        return tower_gradvars\n",
    "\n",
    "    if have_nccl and nccl_on:\n",
    "        new_tower_grads = []\n",
    "        contig_list = []\n",
    "        for d, grad_list in zip(devices, tower_gradvars):\n",
    "            with tf.device(d):\n",
    "                flat_grads = [tf.reshape(g, [-1]) for (g, _) in grad_list]\n",
    "                contig_grads = tf.concat(flat_grads, 0)\n",
    "                contig_list.append(contig_grads)\n",
    "\n",
    "        summed_grads = nccl.all_sum(contig_list)\n",
    "        for d, s, grad_list in zip(devices, summed_grads, tower_gradvars):\n",
    "            with tf.device(d):\n",
    "                new_grad_list = [];\n",
    "                sizes = [tf.size(g) for (g, _) in grad_list]\n",
    "                flat_grads = tf.split(s, sizes)\n",
    "                for newg, (oldg, v) in zip(flat_grads, grad_list):\n",
    "                    newg = tf.reshape(newg, tf.shape(oldg))\n",
    "                    newg *= 1. / len(devices)\n",
    "                    new_grad_list.append((newg, v))\n",
    "                new_tower_grads.append(new_grad_list)\n",
    "        return new_tower_grads\n",
    "    else:\n",
    "        num_devices = len(tower_gradvars)\n",
    "        avg_gradvars = []\n",
    "        for layer in zip(*tower_gradvars):\n",
    "            grads_on_devices, vars_on_devices = zip(*layer)\n",
    "            with tf.device(param_server_device):\n",
    "                avg_grad = tf.reduce_mean(tf.stack(grads_on_devices), 0)\n",
    "            avg_grads_on_devices = [avg_grad]*num_devices\n",
    "            avg_gradvars_on_devices = zip(*(avg_grads_on_devices, vars_on_devices))\n",
    "            avg_gradvars.append(avg_gradvars_on_devices)\n",
    "        return list(zip(*avg_gradvars))\n",
    "\n",
    "def all_sync_params(tower_params, devices):\n",
    "    \"\"\"Assigns the params from the first tower to all others\"\"\"\n",
    "    if len(devices) == 1:\n",
    "        return tf.no_op()\n",
    "    sync_ops = []\n",
    "    if have_nccl and nccl_on:\n",
    "        for param_on_devices in zip(*tower_params):\n",
    "            # Note: param_on_devices is [paramX_gpu0, paramX_gpu1, ...]\n",
    "            param0 = param_on_devices[0]\n",
    "            send_op, received_tensors = nccl.broadcast(param0, devices[1:])\n",
    "            sync_ops.append(send_op)\n",
    "            for device, param, received in zip(devices[1:],\n",
    "                                               param_on_devices[1:],\n",
    "                                               received_tensors):\n",
    "                with tf.device(device):\n",
    "                    sync_op = param.assign(received)\n",
    "                    sync_ops.append(sync_op)\n",
    "    else:\n",
    "        params0 = tower_params[0]\n",
    "        for device, params in zip(devices, tower_params):\n",
    "            with tf.device(device):\n",
    "                for param, param0 in zip(params, params0):\n",
    "                    sync_op = param.assign(param0.read_value())\n",
    "                    sync_ops.append(sync_op)\n",
    "    return tf.group(*sync_ops)\n",
    "\n",
    "class FeedForwardTrainer(object):\n",
    "    def __init__(self, preprocessor, loss_func, nstep_per_epoch=None):\n",
    "        self.image_preprocessor = preprocessor\n",
    "        self.loss_func          = loss_func\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.global_step = tf.get_variable(\n",
    "                'global_step', [],\n",
    "                initializer=tf.constant_initializer(0),\n",
    "                dtype=tf.int64,\n",
    "                trainable=False)\n",
    "        self.learning_rate = tf.train.exponential_decay(\n",
    "            learning_rate,\n",
    "            self.global_step,\n",
    "            decay_steps=lr_decay_epochs*nstep_per_epoch,\n",
    "            decay_rate=lr_decay_rate,\n",
    "            staircase=True)\n",
    "    def make_optimizer(self):\n",
    "        opt = tf.train.MomentumOptimizer(self.learning_rate, momentum,\n",
    "                                         use_nesterov=True)\n",
    "        return opt\n",
    "    def training_step(self, total_batch_size, devices):\n",
    "        preload_ops = [] # CPU pre-load\n",
    "        gpucopy_ops = [] # H2D transfer\n",
    "        self.tower_params = []\n",
    "        tower_losses   = []\n",
    "        tower_gradvars = []\n",
    "        tower_top1s    = []\n",
    "        tower_top5s    = []\n",
    "        if type(self.image_preprocessor) is NdllPreprocessor:\n",
    "            dev_images, dev_labels = self.image_preprocessor.get_device_minibatch()\n",
    "        else:\n",
    "            with tf.device('/cpu:0'):\n",
    "                dev_images, dev_labels = self.image_preprocessor.device_minibatches(\n",
    "                    total_batch_size)\n",
    "\n",
    "        # Each device has its own copy of the model, referred to as a tower\n",
    "        for device_num, device in enumerate(devices):\n",
    "            if type(self.image_preprocessor) is NdllPreprocessor:\n",
    "                images, labels = dev_images, dev_labels\n",
    "            else:\n",
    "                images, labels = dev_images[device_num], dev_labels[device_num]\n",
    "                with tf.device('/cpu:0'):\n",
    "                    # Stage images on the host\n",
    "                    preload_op, (images, labels) = stage([images, labels])\n",
    "                    preload_ops.append(preload_op)\n",
    "\n",
    "            with tf.device(device):\n",
    "                if type(self.image_preprocessor) is ImagePreprocessor:\n",
    "                    # Copy images from host to device\n",
    "                    gpucopy_op, (images, labels) = stage([images, labels])\n",
    "                    gpucopy_ops.append(gpucopy_op)\n",
    "\n",
    "                # Evaluate the loss and compute the gradients\n",
    "                with tf.variable_scope(\n",
    "                        'GPU_%i' % device_num,\n",
    "                        # Force all variables to be stored as float32\n",
    "                        custom_getter=float32_variable_storage_getter) \\\n",
    "                        as var_scope, \\\n",
    "                     tf.name_scope('tower_%i' % device_num):\n",
    "                    loss, logits = self.loss_func(images, labels, var_scope)\n",
    "                    tower_losses.append(loss)\n",
    "                    params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                               scope=var_scope.name)\n",
    "                    self.tower_params.append(params)\n",
    "                    # Apply loss scaling to improve numerical stability\n",
    "                    if loss_scale != 1:\n",
    "                        scale = loss_scale\n",
    "                        grads  = [grad*(1./scale)\n",
    "                                  for grad in tf.gradients(loss*scale, params)]\n",
    "                    else:\n",
    "                        grads = tf.gradients(loss, params)\n",
    "                    gradvars = list(zip(grads, params))\n",
    "                    tower_gradvars.append(gradvars)\n",
    "                    with tf.device('/cpu:0'): # No in_top_k implem on GPU\n",
    "                        labels = tf.cast(labels, tf.int32)\n",
    "                        top1 = tf.reduce_mean(\n",
    "                            tf.cast(tf.nn.in_top_k(logits, labels, 1), tf.float32))\n",
    "                        top5 = tf.reduce_mean(\n",
    "                            tf.cast(tf.nn.in_top_k(logits, labels, 5), tf.float32))\n",
    "                    tower_top1s.append(top1)\n",
    "                    tower_top5s.append(top5)\n",
    "        # Average the losses and gradients from each tower\n",
    "        with tf.device('/cpu:0'):\n",
    "            total_loss = tf.reduce_mean(tower_losses)\n",
    "            total_top1 = tf.reduce_mean(tower_top1s)\n",
    "            total_top5 = tf.reduce_mean(tower_top5s)\n",
    "            averager = tf.train.ExponentialMovingAverage(0.90, name='loss_avg',\n",
    "                                                         zero_debias=True)\n",
    "            avg_op = averager.apply([total_loss])\n",
    "            total_loss_avg = averager.average(total_loss)\n",
    "            # Note: This must be done _after_ the averager.average() call\n",
    "            #         because it changes total_loss into a new object.\n",
    "            with tf.control_dependencies([avg_op]):\n",
    "                total_loss     = tf.identity(total_loss)\n",
    "                total_loss_avg = tf.identity(total_loss_avg)\n",
    "            tf.summary.scalar('total loss raw', total_loss)\n",
    "            tf.summary.scalar('total loss avg', total_loss_avg)\n",
    "            tf.summary.scalar('train accuracy top-1 %', 100.*total_top1)\n",
    "            tf.summary.scalar('train accuracy top-5 %', 100.*total_top5)\n",
    "            tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        tower_gradvars = all_avg_gradients(tower_gradvars, devices)\n",
    "\n",
    "        for grad, var in tower_gradvars[0]:\n",
    "            tf.summary.histogram(var.op.name + '/values', var)\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "        # Apply the gradients to optimize the loss function\n",
    "        train_ops = []\n",
    "        for device_num, device in enumerate(devices):\n",
    "            with tf.device(device):\n",
    "                gradvars = tower_gradvars[device_num]\n",
    "                opt = self.make_optimizer()\n",
    "                train_op = opt.apply_gradients(gradvars)\n",
    "                train_ops.append(train_op)\n",
    "        # Combine all of the ops required for a training step\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) or []\n",
    "        with tf.device('/cpu:0'):\n",
    "            increment_global_step_op = tf.assign_add(self.global_step, 1)\n",
    "        update_ops.append(increment_global_step_op)\n",
    "        self.enqueue_ops = []\n",
    "        self.enqueue_ops.append(tf.group(*preload_ops))\n",
    "        self.enqueue_ops.append(tf.group(*gpucopy_ops))\n",
    "        train_and_update_ops = tf.group(*(train_ops + update_ops))\n",
    "        all_training_ops = (self.enqueue_ops + [train_and_update_ops])\n",
    "        return total_loss_avg, self.learning_rate, all_training_ops\n",
    "    def init(self, sess, devices):\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sync_op = all_sync_params(self.tower_params, devices)\n",
    "        sess.run(init_op)\n",
    "        sess.run(sync_op)\n",
    "    def prefill_pipeline(self, sess):\n",
    "        # Pre-fill the input pipeline with data\n",
    "        for i in range(len(self.enqueue_ops)):\n",
    "            sess.run(self.enqueue_ops[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func = lambda net, images: inference_resnet_v1(net, images, nlayer)\n",
    "\n",
    "def loss_func(images, labels, var_scope):\n",
    "    # Build the forward model\n",
    "    net = GPUNetworkBuilder(\n",
    "        True, dtype=model_dtype)\n",
    "    # Tmp: need to implem shape in the NdllOp\n",
    "    #images.set_shape((FLAGS.batch_size, 3, height, width))\n",
    "    #print(images.shape)\n",
    "    output = model_func(net, images)\n",
    "    # Add final FC layer to produce nclass outputs\n",
    "    logits = net.fully_connected(output, nclass, activation='LINEAR')\n",
    "    if logits.dtype != tf.float32:\n",
    "        logits = tf.cast(logits, tf.float32)\n",
    "    if labels.dtype != tf.int32:\n",
    "        labels = tf.cast(labels, tf.int32)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        logits=logits, labels=labels)\n",
    "    # Add weight decay\n",
    "    if weight_decay is not None and weight_decay != 0.:\n",
    "        params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=var_scope.name)\n",
    "        with net.jit_scope():\n",
    "            l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in params])\n",
    "            if l2_loss.dtype != tf.float32:\n",
    "                l2_loss = tf.cast(l2_loss, tf.float32)\n",
    "            loss += weight_decay * l2_loss\n",
    "    return loss, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "height, width = 224, 224\n",
    "#nstep_per_epoch = NRECORDS / BATCH_SIZE\n",
    "nstep_per_epoch = 1000\n",
    "\n",
    "if NDLL_ON:\n",
    "    preprocessor = NdllPreprocessor(height, width, BATCH_SIZE)\n",
    "else:\n",
    "    preprocessor = ImagePreprocessor(height, width, \"train\")\n",
    "\n",
    "\n",
    "trainer = FeedForwardTrainer(preprocessor, loss_func, nstep_per_epoch)\n",
    "print(\"Building training graph\")\n",
    "devices = ['/gpu:%i' % i for i in range(DEVICES)]\n",
    "total_loss, learning_rate, train_ops = trainer.training_step(\n",
    "    BATCH_SIZE, devices)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove per_process_gpu_memory_fraction once DALI use TF allocator\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "config.intra_op_parallelism_threads = 1\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "trainer.init(sess, devices)\n",
    "\n",
    "print(\"Training\")\n",
    "print(\"  Step Epoch Img/sec   Loss   LR\")\n",
    "\n",
    "oom = False\n",
    "batch_times = []\n",
    "nstep = nstep_per_epoch\n",
    "step0 = int(sess.run(trainer.global_step))\n",
    "\n",
    "for step in range(step0, nstep):\n",
    "    ops_to_run = [total_loss, learning_rate] + train_ops\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        loss, lr = sess.run(ops_to_run)[:2]\n",
    "        elapsed = time.time() - start_time\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interrupt\")\n",
    "        break\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        elapsed = -1.\n",
    "        loss    = 0.\n",
    "        lr      = -1\n",
    "        oom = True\n",
    "\n",
    "    if step >= nstep_burnin:\n",
    "        batch_times.append(elapsed)\n",
    "    img_per_sec = total_batch_size / elapsed\n",
    "    effective_accuracy = 100. / math.exp(min(loss,20.))\n",
    "    if step == 0 or (step+1) % display_every == 0:\n",
    "        epoch = step*total_batch_size // NRECORDS\n",
    "        print(\"%6i %5i %7.1f %7.3f %7.5f\" % (\n",
    "            step+1, epoch+1, img_per_sec, loss, lr))\n",
    "    if oom:\n",
    "        break\n",
    "\n",
    "nstep = len(batch_times)\n",
    "if nstep > 0:\n",
    "    batch_times = np.array(batch_times)\n",
    "    speeds = total_batch_size / batch_times\n",
    "    speed_mean = np.mean(speeds)\n",
    "    if nstep > 2:\n",
    "        speed_uncertainty = np.std(speeds, ddof=1) / np.sqrt(float(nstep))\n",
    "    else:\n",
    "        speed_uncertainty = float('nan')\n",
    "    speed_madstd = 1.4826*np.median(np.abs(speeds - np.median(speeds)))\n",
    "    speed_jitter = speed_madstd\n",
    "    print('-' * 64)\n",
    "    print('Images/sec: %.1f +/- %.1f (jitter = %.1f)' % (\n",
    "        speed_mean, speed_uncertainty, speed_jitter))\n",
    "    print('-' * 64)\n",
    "else:\n",
    "    print(\"No results, did not get past burn-in phase (%i steps)\" %\n",
    "          nstep_burnin)\n",
    "\n",
    "if oom:\n",
    "    print(\"Out of memory error detected, exiting\")\n",
    "    sys.exit(-2)                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

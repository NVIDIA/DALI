{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c07b3c",
   "metadata": {},
   "source": [
    "# WebDataset reader\n",
    "Here is an example of how one may combine the webdataset (source: https://github.com/webdataset/webdataset) with the DALI pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b488055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali as dali\n",
    "import webdataset as wds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "root_path = os.path.join(os.environ[\"DALI_EXTRA_PATH\"], \"db\", \"webdataset\")\n",
    "tar_dataset_paths = [os.path.join(root_path, data_file) \n",
    "                        for data_file in [\"devel-0.tar\", \"devel-1.tar\", \"devel-2.tar\"]]\n",
    "\n",
    "folder_dataset_files = sorted(glob.glob(os.path.join(root_path, \"devel-[012]\", \"*.jpg\")), \n",
    "                              key = lambda s: (\n",
    "                                  s[:s.rfind('/')],\n",
    "                                  int(s[s.rfind('/') + 1:s.find(\".jpg\")])\n",
    "                              )) # For lexicographical order of files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b704af8",
   "metadata": {},
   "source": [
    "## Defining the reader\n",
    "Below is a generator used for the buffered shuffling of the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694b063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffered_shuffle(generator, initial_fill, seed):\n",
    "    assert(initial_fill > 0)\n",
    "    buffer = []\n",
    "    \n",
    "    # Holds a separate random lib state to avoid side effects\n",
    "    random_current_state = random.getstate()\n",
    "    random.seed(seed)\n",
    "    random_state = random.getstate()\n",
    "    random.setstate(random_current_state)\n",
    "    \n",
    "    try:\n",
    "        while len(buffer) < initial_fill: # Fills in the random buffer\n",
    "            buffer.append(next(generator))\n",
    "\n",
    "\n",
    "        while True: # Selects a random sample from the buffer and then fills it back in with a new one\n",
    "            \n",
    "            # Holds a separate random lib state to avoid side effects\n",
    "            random_current_state = random.getstate()\n",
    "            random.setstate(random_state)\n",
    "            idx = random.randint(0, initial_fill-1)\n",
    "            random_state = random.getstate()\n",
    "            random.setstate(random_current_state)\n",
    "\n",
    "            yield buffer[idx]\n",
    "            buffer[idx] = next(generator)\n",
    "            \n",
    "    except StopIteration: # When the generator runs out of the samples flushes our the buffer\n",
    "        \n",
    "        # Holds a separate random lib state to avoid side effects\n",
    "        random_current_state = random.getstate()\n",
    "        random.setstate(random_state)\n",
    "        random.shuffle(buffer)\n",
    "        random.setstate(random_current_state)\n",
    "\n",
    "        while buffer:\n",
    "            yield buffer[-1]\n",
    "            buffer.pop()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db398cb7",
   "metadata": {},
   "source": [
    "This is a generator for filling in the last batch with the repetition of the last sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88313637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_batch_padding(generator, batch_size):\n",
    "    in_batch_idx = 0\n",
    "    last_item = None\n",
    "    try:\n",
    "        while True: # Keeps track of the last sample and the sample number mod batch_size\n",
    "            last_item = next(generator)\n",
    "            in_batch_idx += 1\n",
    "            if in_batch_idx >= batch_size:\n",
    "                in_batch_idx -= batch_size\n",
    "            yield last_item\n",
    "    except StopIteration: # Repeats the last sample the necessary number of times\n",
    "        while in_batch_idx < batch_size:\n",
    "            yield last_item\n",
    "            in_batch_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf9719",
   "metadata": {},
   "source": [
    "This is a generator for supporting continuous data yielding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_generator(dataset_generator):\n",
    "    dataset = dataset_generator()\n",
    "    while True:\n",
    "        try:\n",
    "            while True:\n",
    "                yield next(dataset)\n",
    "        except StopIteration:\n",
    "            dataset = dataset_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfebc0",
   "metadata": {},
   "source": [
    "And finally the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b6126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_webdataset(\n",
    "    paths, \n",
    "    extensions=None,\n",
    "    random_shuffle=False, \n",
    "    initial_fill=16, \n",
    "    seed=123,\n",
    "    pad_last_batch=False,\n",
    "    read_ahead=False\n",
    "):\n",
    "    if extensions == None:\n",
    "        extensions = ';'.join([\"jpg\", \"jpeg\", \"img\", \"image\", \"pbm\", \"pgm\", \"png\"]) # All supported image formats\n",
    "    if type(extensions) == str:\n",
    "        extensions = (extensions,)\n",
    "    \n",
    "    dataset_generator = lambda: iter(\n",
    "        wds.WebDataset(paths, shardshuffle=False)\n",
    "        .to_tuple(*extensions)\n",
    "        .map_tuple(*((\n",
    "            lambda data: np.frombuffer(data, dtype=np.uint8),)\n",
    "            *len(extensions)))\n",
    "        )\n",
    "    \n",
    "    dataset = dataset_generator()\n",
    "    \n",
    "    if not read_ahead: # if read_ahead is False the cycling is handled by the external generator\n",
    "        dataset = cycle_generator(dataset_generator)\n",
    "    \n",
    "    if random_shuffle:\n",
    "        dataset = buffered_shuffle(dataset, initial_fill, seed)\n",
    "        \n",
    "    if pad_last_batch:\n",
    "        dataset = last_batch_padding(dataset, dali.pipeline.Pipeline.current().max_batch_size)\n",
    "    \n",
    "    if read_ahead:\n",
    "        dataset=list(dataset)\n",
    "    \n",
    "    return fn.external_source(\n",
    "        source=dataset,\n",
    "        parallel=True,\n",
    "        prefetch_queue_depth=2,\n",
    "        num_outputs=len(extensions),\n",
    "        batch=False,\n",
    "        cycle=read_ahead # if read_ahead is True then the cycling is handled by external source\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7c152",
   "metadata": {},
   "source": [
    "We also define a sample data augmentation function for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677153ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_augment(img, seed=123):\n",
    "    img = fn.decoders.image(img)\n",
    "    img = fn.jitter(img.gpu(), seed=seed)\n",
    "    img = fn.resize(img, size = (224, 224))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6424b",
   "metadata": {},
   "source": [
    "## Reader features presentation\n",
    "Below we define a sample pipeline with our external source reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e598d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dali.pipeline_def(batch_size=1024, num_threads=4, device_id=0, py_num_workers=12)\n",
    "def webdataset_pipeline(\n",
    "    paths,\n",
    "    random_shuffle=False, \n",
    "    initial_fill=16, \n",
    "    seed=123,\n",
    "    pad_last_batch=False,\n",
    "    read_ahead=False\n",
    "):\n",
    "    img, label = read_webdataset(paths=paths, \n",
    "                                 extensions=(\"jpg\", \"cls\"),\n",
    "                                 random_shuffle=random_shuffle,\n",
    "                                 initial_fill=initial_fill,\n",
    "                                 seed=seed,\n",
    "                                 pad_last_batch=pad_last_batch,\n",
    "                                 read_ahead=read_ahead)\n",
    "    return decode_augment(img, seed=seed), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471a67e",
   "metadata": {},
   "source": [
    "Which can be then built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25ce3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = webdataset_pipeline(\n",
    "    tar_dataset_paths,   # Paths for the sharded dataset\n",
    "    random_shuffle=True, # Random buffered shuffling on\n",
    "    initial_fill=64,     # The random shuffling buffer\n",
    "    pad_last_batch=True, # Last batch is filled to the full size\n",
    "    read_ahead=True)     # All the data is preloaded into the memory\n",
    "pipeline.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a1fad",
   "metadata": {},
   "source": [
    "And executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff5765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.25207658240106 microseconds/sample\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "batch_size = 1024\n",
    "epochs = 20\n",
    "start = timeit.default_timer()\n",
    "for _ in range(epochs):\n",
    "    pipeline.run()\n",
    "end = timeit.default_timer()\n",
    "print((end-start)/epochs/batch_size*1e6, \"microseconds/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f1ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

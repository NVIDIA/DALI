{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In this example we will go through the steps to build a DALI audio processing pipeline, including the calculation of a spectrogram. A spectrogram is a representation of a signal (e.g. an audio signal) that shows the evolution of the frequency spectrum in time.\n",
    "\n",
    "Typically, a spectrogram is calculated by computing the fast fourier transform (FFT) over a series of overlapping windows extracted from the original signal. The process of dividing the signal in short term sequences of fixed size and applying FFT on those independently is called Short-time Fourier transform (STFT). The spectrogram is then calculated as the (typically squared) complex magnitude of the STFT.\n",
    "\n",
    "Extracting short term windows of the original image affects the calculated spectrum by producing aliasing artifacts. This is often called spectral leakage. To control/reduce the spectral leakage effect, we use different window functions when extracting the windows. Some examples of window functions are: Hann, Hanning, etc.\n",
    "\n",
    "It is beyond the scope of this example to go deeper into the details of the signal processing concepts we mentioned above. More information can be found here:\n",
    "- [STFT](https://en.wikipedia.org/wiki/Short-time_Fourier_transform)\n",
    "- [Window functions](https://en.wikipedia.org/wiki/Window_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference implementation\n",
    "\n",
    "To verify the correctness of DALI's implementation, we will compare it against librosa (https://librosa.github.io/librosa/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librosa provides an API to calculate the STFT, producing a complex output (i.e. complex numbers). It is then trivial to calculate the power spectrum from the complex STFT by the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafal/mydali/build/venv/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/home/rafal/mydali/build/venv/lib/python3.6/site-packages/librosa/util/example_data/Kevin_MacLeod_-_Vibe_Ace.ogg': File contains data in an unimplemented format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fbf5b7155339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load sample audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_audio_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate the spectrogram as the square of the complex magnitude of the STFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mydali/build/venv/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# All backends failed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Size of the FFT, which will also be used as the window length\n",
    "n_fft=2048\n",
    "\n",
    "# Step or stride between windows. If the step is smaller than the window lenght, the windows will overlap\n",
    "hop_length=512\n",
    "\n",
    "# Load sample audio file\n",
    "y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "\n",
    "# Calculate the spectrogram as the square of the complex magnitude of the STFT\n",
    "spectrogram_librosa = np.abs(librosa.stft(\n",
    "    y, n_fft=n_fft, hop_length=hop_length, win_length=n_fft, window='hann')) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now transform the spectrogram output to a logarithmic scale by transforming the amplitude to decibels. While doing so we will also normalize the spectrogram so that its maximum represent the 0 dB point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_librosa_db = librosa.power_to_db(spectrogram_librosa, ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to display the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(spectrogram_librosa_db, sr=sr, y_axis='log', x_axis='time', hop_length=hop_length)\n",
    "plt.title('Reference power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the spectrogram using DALI\n",
    "\n",
    "To demonstrate DALI's Spectrogram operator we will define a DALI pipeline, whose input will be provided externally with the help of ExternalSource operator. For demonstration purposes, we can just feed the same input in every iteration, as we will be only calculating one spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali as dali\n",
    "\n",
    "class SpectrogramPipeline(Pipeline):\n",
    "    def __init__(self, device, batch_size, nfft, window_length, window_step, num_threads=1, device_id=0):\n",
    "        super(SpectrogramPipeline, self).__init__(batch_size, num_threads, device_id)\n",
    "        self.device = device\n",
    "        \n",
    "        self.batch_data = []\n",
    "        y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "        for _ in range(batch_size):\n",
    "            self.batch_data.append(np.array(y, dtype=np.float32))\n",
    "        \n",
    "        self.external_source = ops.ExternalSource()\n",
    "        self.spectrogram = ops.Spectrogram(device=self.device, \n",
    "                                           nfft=nfft, \n",
    "                                           window_length=window_length,\n",
    "                                           window_step=window_step)\n",
    "\n",
    "    def define_graph(self):\n",
    "        self.data = self.external_source()\n",
    "        out = self.data.gpu() if self.device == 'gpu' else self.data\n",
    "        out = self.spectrogram(out)\n",
    "        return out\n",
    "\n",
    "    def iter_setup(self):\n",
    "        self.feed_input(self.data, self.batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the pipeline defined, we can now just build it and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = SpectrogramPipeline(device='cpu', batch_size=1, nfft=n_fft, window_length=n_fft, window_step=hop_length)\n",
    "pipe.build()\n",
    "outputs = pipe.run()\n",
    "spectrogram_dali = outputs[0].at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and display it as we did with the reference implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_dali_db = librosa.power_to_db(spectrogram_dali, ref=np.max)\n",
    "librosa.display.specshow(spectrogram_dali_db, sr=sr, y_axis='log', x_axis='time', hop_length=hop_length)\n",
    "plt.title('DALI power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last sanity check, we can verify that the numerical difference between the reference implementation and DALI's is insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average error: {0:.5f} dB\".format(np.mean(np.abs(spectrogram_dali_db - spectrogram_librosa_db))))\n",
    "assert(np.allclose(spectrogram_dali_db, spectrogram_librosa_db, atol=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel spectrogram\n",
    "\n",
    "The mel scale is a non-linear transformation of frequency scale based on the perception of pitches. The mel scale is calculated so that two pairs of frequencies separated by a delta in the mel scale are perceived by humans as being equidistant. More information can be found here: https://en.wikipedia.org/wiki/Mel_scale.\n",
    "\n",
    "In machine learning applications involving speech and audio, we typically want to represent the power spectrogram in the mel scale domain. We do that by applying a bank of overlapping triangular filters that compute the energy of the spectrum in each band.\n",
    "\n",
    "Typically, we want the mel spectrogram represented in decibels. We can calculate a mel spectrogram in decibels by using the following DALI pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpectrogramPipeline(Pipeline):\n",
    "    def __init__(self, device, batch_size, nfft, window_length, window_step, num_threads=1, device_id=0):\n",
    "        super(MelSpectrogramPipeline, self).__init__(batch_size, num_threads, device_id)\n",
    "        self.device = device\n",
    "        \n",
    "        self.batch_data = []\n",
    "        y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "        for _ in range(batch_size):\n",
    "            self.batch_data.append(np.array(y, dtype=np.float32))\n",
    "        \n",
    "        self.external_source = ops.ExternalSource()\n",
    "        self.spectrogram = ops.Spectrogram(device=self.device, \n",
    "                                           nfft=nfft, \n",
    "                                           window_length=window_length,\n",
    "                                           window_step=window_step)\n",
    "        \n",
    "        self.mel_fbank = ops.MelFilterBank(device=self.device,\n",
    "                                           sample_rate=sr,\n",
    "                                           nfilter = 128,\n",
    "                                           freq_high = 8000.0)\n",
    "        \n",
    "        self.dB = ops.ToDecibels(device=self.device, \n",
    "                                 multiplier = 10.0,\n",
    "                                 cutoff_db = -80)\n",
    "\n",
    "    def define_graph(self):\n",
    "        self.data = self.external_source()\n",
    "        out = self.data.gpu() if self.device == 'gpu' else self.data\n",
    "        out = self.spectrogram(out)\n",
    "        out = self.mel_fbank(out)\n",
    "        out = self.dB(out)\n",
    "        return out\n",
    "\n",
    "    def iter_setup(self):\n",
    "        self.feed_input(self.data, self.batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MelSpectrogramPipeline(device='cpu', batch_size=1, nfft=n_fft, window_length=n_fft, window_step=hop_length)\n",
    "pipe.build()\n",
    "outputs = pipe.run()\n",
    "mel_spectrogram_dali_db = outputs[0].at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now verify that it produces the same result as Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(mel_spectrogram_dali_db, sr=sr, y_axis='mel', x_axis='time', hop_length=hop_length)\n",
    "plt.title('DALI Mel-frequency spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_librosa = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "mel_spectrogram_librosa_db = librosa.power_to_db(mel_spectrogram_librosa, ref=np.max)\n",
    "assert(np.allclose(mel_spectrogram_dali_db, mel_spectrogram_librosa_db, atol=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel-frequency cepstral coefficients (MFCCs)\n",
    "\n",
    "MFCCs are an alternative representation of the Mel-frequency spectrogram often used in audio applications. The MFCCs are calculated by applying the discrete cosine transform (DCT) to a mel-frequency spectrogram. \n",
    "\n",
    "DALI's implementation of DCT uses uses the formulas described in https://en.wikipedia.org/wiki/Discrete_cosine_transform\n",
    "\n",
    "\n",
    "In addition to the DCT, a cepstral filter (also known as *liftering*) can be applied to emphasize higher order coefficients.\n",
    "\n",
    "A *liftered* cepstral coefficient is calculated according to the formula\n",
    "$$\n",
    "\\widehat{\\text{MFCC}_i} = w_{i} \\cdot \\text{MFCC}_{i}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "w_i = 1 + \\frac{L}{2}\\sin\\Big(\\frac{\\pi i}{L}\\Big)\n",
    "$$\n",
    "where $L$ is the *liftering* coefficient.\n",
    "\n",
    "More information about MFCC can be found here: https://en.wikipedia.org/wiki/Mel-frequency_cepstrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use DALI's MFCC operator to transform the mel-spectrogram into a set of MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCPipeline(Pipeline):\n",
    "    def __init__(self, device, batch_size, nfft, window_length, window_step, \n",
    "                 dct_type, n_mfcc, normalize, lifter, num_threads=1, device_id=0):\n",
    "        super(MFCCPipeline, self).__init__(batch_size, num_threads, device_id)\n",
    "        self.device = device\n",
    "        \n",
    "        self.batch_data = []\n",
    "        y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "        for _ in range(batch_size):\n",
    "            self.batch_data.append(np.array(y, dtype=np.float32))\n",
    "        \n",
    "        self.external_source = ops.ExternalSource()\n",
    "        self.spectrogram = ops.Spectrogram(device=self.device, \n",
    "                                           nfft=nfft, \n",
    "                                           window_length=window_length,\n",
    "                                           window_step=window_step)\n",
    "        \n",
    "        self.mel_fbank = ops.MelFilterBank(device=self.device,\n",
    "                                           sample_rate=sr,\n",
    "                                           nfilter = 128,\n",
    "                                           freq_high = 8000.0)\n",
    "        \n",
    "        self.dB = ops.ToDecibels(device=self.device, \n",
    "                                 multiplier = 10.0,\n",
    "                                 cutoff_db = -80.0)\n",
    "        \n",
    "        self.mfcc = ops.MFCC(device=self.device, \n",
    "                             axis=0, \n",
    "                             dct_type=dct_type, \n",
    "                             n_mfcc=n_mfcc, \n",
    "                             normalize=normalize, \n",
    "                             lifter=lifter)\n",
    "\n",
    "    def define_graph(self):\n",
    "        self.data = self.external_source()\n",
    "        out = self.data.gpu() if self.device == 'gpu' else self.data\n",
    "        out = self.spectrogram(out)\n",
    "        out = self.mel_fbank(out)\n",
    "        out = self.dB(out)\n",
    "        out = self.mfcc(out)\n",
    "        return out\n",
    "\n",
    "    def iter_setup(self):\n",
    "        self.feed_input(self.data, self.batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run the pipeline and display the output as we did previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MFCCPipeline(device='cpu', batch_size=1, nfft=n_fft, window_length=n_fft, window_step=hop_length, \n",
    "                    dct_type=2, n_mfcc=40, normalize=True, lifter=0)\n",
    "pipe.build()\n",
    "outputs = pipe.run()\n",
    "mfccs_dali = outputs[0].at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs_dali, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC (DALI)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, let's verify that this implementation produces the same result as Librosa. Please note, we are comparing the ortho-normalized MFCCs, as Librosa's DCT implementation uses a different formula which causes the output to be scaled by a factor of 2 when we compare it with the Wikipedia's formulae. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_librosa = librosa.feature.mfcc(S=mel_spectrogram_librosa_db,\n",
    "                                     dct_type=2, n_mfcc=40, norm='ortho', lifter=0)\n",
    "assert(np.allclose(mfccs_librosa, mfccs_dali, atol=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

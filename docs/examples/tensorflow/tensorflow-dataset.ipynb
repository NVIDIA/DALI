{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow DALI plugin: DALI tf.data.Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this tutorial you will find out how to integrate a DALI pipeline with tf.data API and use it in training with various TensorFlow APIs. We will use well known MNIST dataset converted to JPEGs. You can find it in DALI_extra repository ready to use.\n",
    "\n",
    "Let's start with creating a pipeline to read MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali as dali\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to MNIST dataset\n",
    "data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/training/')\n",
    "\n",
    "\n",
    "class MnistPipeline(Pipeline):\n",
    "    def __init__(self, device, device_id=0, num_threads=4, seed=0):\n",
    "        super(MnistPipeline, self).__init__(\n",
    "            batch_size, num_threads, device_id, seed)\n",
    "        self.device = device\n",
    "        self.reader = ops.Caffe2Reader(path=data_path, random_shuffle=True)\n",
    "        self.decode = ops.ImageDecoder(\n",
    "            device='mixed' if device is 'gpu' else 'cpu',\n",
    "            output_type=types.GRAY)\n",
    "        self.cmn = ops.CropMirrorNormalize(\n",
    "            device=device,\n",
    "            output_dtype=types.FLOAT,\n",
    "            image_type=types.GRAY,\n",
    "            mean=[0.],\n",
    "            std=[255.],\n",
    "            output_layout=types.NCHW)\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.reader(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        if self.device is 'gpu':\n",
    "            labels = labels.gpu()\n",
    "        images = self.cmn(images)\n",
    "\n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some parameters of the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "hidden_size = 128\n",
    "epochs = 5\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of the usuall workflow of building a pipeline we wrap it with `DALIDataset` object from DALI TensorFlow plugin. This class is compatible with `tf.data.Dataset`. We need to pass expected shapes and types of the outputs with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali.plugin.tf as dali_tf\n",
    "try:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "#     tf.compat.v1.disable_eager_execution()\n",
    "except:\n",
    "    import tensorflow as tf\n",
    "\n",
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='cpu', device_id=0)\n",
    "\n",
    "# Define shapes and types of the outputs\n",
    "shapes = [\n",
    "    (batch_size, image_size, image_size),\n",
    "    (batch_size)]\n",
    "dtypes = [\n",
    "    tf.float32,\n",
    "    tf.int32]\n",
    "\n",
    "# Create dataset\n",
    "mnist_set = dali_tf.DALIDataset(\n",
    "    pipeline=mnist_pipeline,\n",
    "    batch_size=batch_size,\n",
    "    shapes=shapes,\n",
    "    dtypes=dtypes,\n",
    "    device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start the training. \n",
    "\n",
    "### Keras\n",
    "\n",
    "First, we will pass `mnist_set` to `tf.keras` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "    tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Train using DALI dataset\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it was very easy to integrate DALI pipeline with `tf.keras` API.\n",
    "\n",
    "Above code performed the training usgin the CPU. We can easily move the whole processing to the GPU. Both the DALI pipelien and the Keras model will be using the GPU without any CPU buffer between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "\n",
    "# Define the model and place it on the GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "        tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "        tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "# Train on the GPU. Data pipeline will be using the GPU as well.\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all that was needed to use the GPU as a training accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Estimators\n",
    "\n",
    "This part of the tutorial focuses on how to use `tf.estimator` API with DALI dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns for Estimator\n",
    "feature_columns = [tf.feature_column.numeric_column(\n",
    "    \"images\", shape=[image_size, image_size])]\n",
    "\n",
    "# And the run config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir='/tmp/tensorflow-checkpoints',\n",
    "    device_fn=lambda op: '/gpu:0')\n",
    "\n",
    "# Finally create the model based on `DNNClassifier`\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[hidden_size],\n",
    "    n_classes=num_classes,\n",
    "    dropout=dropout,\n",
    "    config=run_config,\n",
    "    optimizer='Adam')\n",
    "\n",
    "# In tf.estimator API data is passed with the function returning the dataset\n",
    "# We define this function to return DALI dataset placed on the GPU\n",
    "def train_data_fn():\n",
    "    with tf.device('/gpu:0'):\n",
    "        mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "        mnist_set = dali_tf.DALIDataset(\n",
    "            pipeline=mnist_pipeline,\n",
    "            batch_size=batch_size,\n",
    "            shapes=shapes,\n",
    "            dtypes=dtypes,\n",
    "            device_id=0)\n",
    "        mnist_set = mnist_set.map(\n",
    "            lambda features, labels: ({'images': features}, labels))\n",
    "        \n",
    "    return mnist_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up we are ready to run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the training\n",
    "model.train(input_fn=train_data_fn, steps=epochs * iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(input_fn=train_data_fn, steps=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom models and training loops\n",
    "\n",
    "Finally, last part of this tutorial focuses on integrating DALI dataset with custom models and training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    daliset = train_data_fn()\n",
    "\n",
    "    iterator = tf.data.make_initializable_iterator(daliset)\n",
    "    images, labels = iterator.get_next()\n",
    "\n",
    "    images = tf.reshape(images, [batch_size, image_size*image_size])\n",
    "    labels = tf.reshape(\n",
    "        tf.one_hot(labels, labels_size),\n",
    "        [batch_size, labels_size])\n",
    "    \n",
    "    with variable_scope('mnist_net', reuse=False):\n",
    "        images = tf.layers.flatten(images)\n",
    "        images = tf.layers.dense(images, hidden_size, activation=tf.nn.relu)\n",
    "        images = tf.layers.dropout(images, rate=dropout, training=True)\n",
    "        images = tf.layers.dense(images, labels_size, activation=tf.nn.softmax)\n",
    "\n",
    "    logits_train = images\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=labels))\n",
    "    train_step = AdamOptimizer().minimize(loss_op)\n",
    "\n",
    "    correct_pred = tf.equal(\n",
    "            tf.argmax(logits_train, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

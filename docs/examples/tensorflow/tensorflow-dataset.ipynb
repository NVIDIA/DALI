{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow DALI plugin: DALI tf.data.Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this tutorial you will find out how to integrate a DALI pipeline with tf.data API and use it in training with various TensorFlow APIs. We will use well known MNIST dataset converted to JPEGs. You can find it in DALI_extra repository ready to use.\n",
    "\n",
    "Let's start with creating a pipeline to read MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali as dali\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to MNIST dataset\n",
    "data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/training/')\n",
    "\n",
    "\n",
    "class MnistPipeline(Pipeline):\n",
    "    def __init__(self, device, device_id=0, num_threads=4, seed=0):\n",
    "        super(MnistPipeline, self).__init__(\n",
    "            batch_size, num_threads, device_id, seed)\n",
    "        self.device = device\n",
    "        self.reader = ops.FileReader(file_root=data_path, random_shuffle=True)\n",
    "        self.decode = ops.ImageDecoder(\n",
    "            device='mixed' if device is 'gpu' else 'cpu',\n",
    "            output_type=types.GRAY)\n",
    "        self.cmn = ops.CropMirrorNormalize(\n",
    "            device=device,\n",
    "            output_dtype=types.FLOAT,\n",
    "            image_type=types.GRAY,\n",
    "            mean=[0.],\n",
    "            std=[255.],\n",
    "            output_layout=types.NCHW)\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.reader(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        if self.device is 'gpu':\n",
    "            labels = labels.gpu()\n",
    "        images = self.cmn(images)\n",
    "\n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some parameters of the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "hidden_size = 128\n",
    "epochs = 5\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of the usuall workflow of building a pipeline we wrap it with `DALIDataset` object from DALI TensorFlow plugin. This class is compatible with `tf.data.Dataset`. We need to pass expected shapes and types of the outputs with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali.plugin.tf as dali_tf\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='cpu', device_id=0)\n",
    "\n",
    "# Define shapes and types of the outputs\n",
    "shapes = [\n",
    "    (batch_size, image_size, image_size),\n",
    "    (batch_size)]\n",
    "dtypes = [\n",
    "    tf.float32,\n",
    "    tf.int32]\n",
    "\n",
    "# Create dataset\n",
    "mnist_set = dali_tf.DALIDataset(\n",
    "    pipeline=mnist_pipeline,\n",
    "    batch_size=batch_size,\n",
    "    shapes=shapes,\n",
    "    dtypes=dtypes,\n",
    "    device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start the training. \n",
    "\n",
    "### Keras\n",
    "\n",
    "First, we will pass `mnist_set` to `tf.keras` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 steps\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.9833 - accuracy: 0.7075\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.8675\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8788\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.9003\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4dbc272e48>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "    tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Train using DALI dataset\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it was very easy to integrate DALI pipeline with `tf.keras` API.\n",
    "\n",
    "Above code performed the training usgin the CPU. We can easily move the whole processing to the GPU. Both the DALI pipelien and the Keras model will be using the GPU without any CPU buffer between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 steps\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.9880 - accuracy: 0.7047\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8769\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8856\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.9038\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4aa52bcbe0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "\n",
    "# Define the model and place it on the GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "        tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "        tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "# Train on the GPU. Data pipeline will be using the GPU as well.\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all that was needed to use the GPU as a training accelerator.\n",
    "\n",
    "### Estimators\n",
    "\n",
    "In the next section we will use `tf.estimator` API instead of the `tf.keras`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzd615gvd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzd615gvd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4a84ae7550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the feature columns\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "feature_columns = [tf.feature_column.numeric_column(\n",
    "    \"images\", shape=[image_size, image_size])]\n",
    "\n",
    "# And the run config\n",
    "# run_config = tf.estimator.RunConfig(\n",
    "#     model_dir='/tmp/tensorflow-checkpoints',\n",
    "#     device_fn=lambda op: '/gpu:0')\n",
    "\n",
    "# Finally create the model\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[hidden_size],\n",
    "    n_classes=num_classes,\n",
    "    dropout=dropout,\n",
    "#     config=run_config,\n",
    "    optimizer='Adam')\n",
    "\n",
    "# In tf.estimator data is passed with the function returning the dataset\n",
    "mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "\n",
    "def train_data_fn():\n",
    "#     with tf.device('/gpu:0'):\n",
    "    mnist_set = dali_tf.DALIDataset(\n",
    "        pipeline=mnist_pipeline,\n",
    "        batch_size=batch_size,\n",
    "        shapes=shapes,\n",
    "        dtypes=dtypes,\n",
    "        device_id=0)\n",
    "    mnist_set = mnist_set.map(\n",
    "        lambda features, labels: ({'images': features}, labels))\n",
    "        \n",
    "    return mnist_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzd615gvd/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmpzd615gvd/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.5080383, step = 500\n",
      "INFO:tensorflow:global_step/sec: 207.625\n",
      "INFO:tensorflow:loss = 0.4004699, step = 600 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.015\n",
      "INFO:tensorflow:loss = 0.17886795, step = 700 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.544\n",
      "INFO:tensorflow:loss = 0.15201095, step = 800 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.254\n",
      "INFO:tensorflow:loss = 0.18331778, step = 900 (0.475 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpzd615gvd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06891136.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f4aa5572780>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the training\n",
    "model.train(input_fn=train_data_fn, steps=epochs * iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow DALI plugin: DALI tf.data.Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this tutorial you will find out how to integrate a DALI pipeline with tf.data API and use it in training with various TensorFlow APIs. We will use well known MNIST dataset converted to JPEGs. You can find it in DALI_extra repository ready to use.\n",
    "\n",
    "Let's start with creating a pipeline to read MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali as dali\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to MNIST dataset\n",
    "data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/training/')\n",
    "\n",
    "\n",
    "class MnistPipeline(Pipeline):\n",
    "    def __init__(self, device, device_id=0, num_threads=4, seed=0):\n",
    "        super(MnistPipeline, self).__init__(\n",
    "            batch_size, num_threads, device_id, seed)\n",
    "        self.device = device\n",
    "        self.reader = ops.Caffe2Reader(path=data_path, random_shuffle=True)\n",
    "        self.decode = ops.ImageDecoder(\n",
    "            device='mixed' if device is 'gpu' else 'cpu',\n",
    "            output_type=types.GRAY)\n",
    "        self.cmn = ops.CropMirrorNormalize(\n",
    "            device=device,\n",
    "            output_dtype=types.FLOAT,\n",
    "            image_type=types.GRAY,\n",
    "            mean=[0.],\n",
    "            std=[255.],\n",
    "            output_layout=types.NCHW)\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.reader(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        if self.device is 'gpu':\n",
    "            labels = labels.gpu()\n",
    "        images = self.cmn(images)\n",
    "\n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some parameters of the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "hidden_size = 128\n",
    "epochs = 5\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of the usuall workflow of building a pipeline we wrap it with `DALIDataset` object from DALI TensorFlow plugin. This class is compatible with `tf.data.Dataset`. We need to pass expected shapes and types of the outputs with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali.plugin.tf as dali_tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='cpu', device_id=0)\n",
    "\n",
    "# Define shapes and types of the outputs\n",
    "shapes = [\n",
    "    (batch_size, image_size, image_size),\n",
    "    (batch_size)]\n",
    "dtypes = [\n",
    "    tf.float32,\n",
    "    tf.int32]\n",
    "\n",
    "# Create dataset\n",
    "mnist_set = dali_tf.DALIDataset(\n",
    "    pipeline=mnist_pipeline,\n",
    "    batch_size=batch_size,\n",
    "    shapes=shapes,\n",
    "    dtypes=dtypes,\n",
    "    device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start the training. \n",
    "\n",
    "### Keras\n",
    "\n",
    "First, we will pass `mnist_set` to `tf.keras` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/awolant/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 100 steps\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.9837 - accuracy: 0.7147\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.8506\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8831\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8919\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2926327588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "    tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "    tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Train using DALI dataset\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it was very easy to integrate DALI pipeline with `tf.keras` API.\n",
    "\n",
    "Above code performed the training usgin the CPU. We can easily move the whole processing to the GPU. Both the DALI pipelien and the Keras model will be using the GPU without any CPU buffer between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 steps\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.0074 - accuracy: 0.7212\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.8528\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8822\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.9022\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f291c370dd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline\n",
    "mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "\n",
    "# Define the model and place it on the GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(image_size, image_size), name='images'),\n",
    "        tf.keras.layers.Flatten(input_shape=(image_size, image_size)),\n",
    "        tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "# Train on the GPU. Data pipeline will be using the GPU as well.\n",
    "model.fit(\n",
    "    mnist_set,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all that was needed to use the GPU as a training accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Estimators\n",
    "\n",
    "This part of the tutorial focuses on how to use `tf.estimator` API with DALI dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tensorflow-checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': <function <lambda> at 0x7f291c163400>, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29284ab7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the feature columns for Estimator\n",
    "feature_columns = [tf.feature_column.numeric_column(\n",
    "    \"images\", shape=[image_size, image_size])]\n",
    "\n",
    "# And the run config\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir='/tmp/tensorflow-checkpoints',\n",
    "    device_fn=lambda op: '/gpu:0')\n",
    "\n",
    "# Finally create the model based on `DNNClassifier`\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[hidden_size],\n",
    "    n_classes=num_classes,\n",
    "    dropout=dropout,\n",
    "    config=run_config,\n",
    "    optimizer='Adam')\n",
    "\n",
    "# In tf.estimator API data is passed with the function returning the dataset\n",
    "# We define this function to return DALI dataset placed on the GPU\n",
    "def train_data_fn():\n",
    "    with tf.device('/gpu:0'):\n",
    "        mnist_pipeline = MnistPipeline(device='gpu', device_id=0)\n",
    "        mnist_set = dali_tf.DALIDataset(\n",
    "            pipeline=mnist_pipeline,\n",
    "            batch_size=batch_size,\n",
    "            shapes=shapes,\n",
    "            dtypes=dtypes,\n",
    "            device_id=0)\n",
    "        mnist_set = mnist_set.map(\n",
    "            lambda features, labels: ({'images': features}, labels))\n",
    "        \n",
    "    return mnist_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up we are ready to run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/awolant/.local/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/awolant/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tensorflow-checkpoints/model.ckpt-500\n",
      "WARNING:tensorflow:From /home/awolant/.local/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tensorflow-checkpoints/model.ckpt.\n",
      "INFO:tensorflow:loss = 43.148834, step = 500\n",
      "INFO:tensorflow:global_step/sec: 216.331\n",
      "INFO:tensorflow:loss = 41.12014, step = 600 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.112\n",
      "INFO:tensorflow:loss = 51.369453, step = 700 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.138\n",
      "INFO:tensorflow:loss = 33.94025, step = 800 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.846\n",
      "INFO:tensorflow:loss = 28.006569, step = 900 (0.444 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tensorflow-checkpoints/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 24.092999.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f290c4b9978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the training\n",
    "model.train(input_fn=train_data_fn, steps=epochs * iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-21T14:29:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tensorflow-checkpoints/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-21-14:29:52\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8425, average_loss = 0.63225484, global_step = 1000, loss = 20.232155\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tensorflow-checkpoints/model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8425,\n",
       " 'average_loss': 0.63225484,\n",
       " 'loss': 20.232155,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=train_data_fn, steps=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom models and training loops\n",
    "\n",
    "Finally, last part of this tutorial focuses on integrating DALI dataset with custom models and training loops. Complete example below shows from start to finish how to use DALI dataset with native TensorFlow model and run training using `tf.Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, accuracy: 0.125\n",
      "Step 100, accuracy: 0.8125\n",
      "Step 200, accuracy: 0.90625\n",
      "Step 300, accuracy: 0.84375\n",
      "Step 400, accuracy: 0.84375\n",
      "Final accuracy:  0.9021875\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = False\n",
    "options.experimental_optimization.autotune = False\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    daliset = dali_tf.DALIDataset(\n",
    "        pipeline=MnistPipeline(device='gpu', device_id=0),\n",
    "        batch_size=batch_size,\n",
    "        shapes=shapes,\n",
    "        dtypes=dtypes,\n",
    "        device_id=0).with_options(options)\n",
    "\n",
    "    iterator = tf.data.make_initializable_iterator(daliset)\n",
    "    images, labels = iterator.get_next()\n",
    "\n",
    "    images = tf.reshape(images, [batch_size, image_size*image_size])\n",
    "    labels = tf.reshape(\n",
    "        tf.one_hot(labels, num_classes),\n",
    "        [batch_size, num_classes])\n",
    "    \n",
    "    with tf.variable_scope('mnist_net', reuse=False):\n",
    "        images = tf.layers.flatten(images)\n",
    "        images = tf.layers.dense(images, hidden_size, activation=tf.nn.relu)\n",
    "        images = tf.layers.dropout(images, rate=dropout, training=True)\n",
    "        images = tf.layers.dense(images, num_classes, activation=tf.nn.softmax)\n",
    "\n",
    "    logits_train = images\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=labels))\n",
    "    train_step = tf.train.AdamOptimizer().minimize(loss_op)\n",
    "\n",
    "    correct_pred = tf.equal(\n",
    "            tf.argmax(logits_train, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(iterator.initializer)\n",
    "\n",
    "        for i in range(epochs * iterations):\n",
    "            sess.run(train_step)\n",
    "            if i % iterations == 0:\n",
    "                train_accuracy = sess.run(accuracy)\n",
    "                print(\"Step %d, accuracy: %g\" % (i, train_accuracy))\n",
    "\n",
    "        final_accuracy = 0\n",
    "        for _ in range(iterations):\n",
    "            final_accuracy = final_accuracy + \\\n",
    "                accuracy.eval()\n",
    "        final_accuracy = final_accuracy / iterations\n",
    "\n",
    "        print('Final accuracy: ', final_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Decoder in DALI\n",
    "\n",
    "This tutorial presents, how to set up simple pipeline, that loads and decodes audio data in DALI. Here we will use simple example from Speech Commands Data Set. While this dataset consists of samples in .wav format, following procudure can be used for most of the well-known formats for audio decoding.\n",
    "\n",
    "## Step-by-step guide\n",
    "1. Let's start by importing handful of utils and DALI itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops            \n",
    "import nvidia.dali.types as types\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 1\n",
    "audio_files = \"audio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used `batch_size` is `1`, to keep things simple.\n",
    "\n",
    "2. Next, let's implement the pipeline. As you can see, it's fairly simple. Firstly, you need to load data from disk (or any other place). Used FileReader is able to load data, as well as it's labels. For more information, refer to FileReader docs. Furthermore, similarly to image data, you can use Reader ops specific for given dataset or dataset format (see COCOReader, LMDBReader)\n",
    "\n",
    "   After loading input, pipeline decodes the AudioData. As stated above, the AudioDecoder operator is able to decode most on well-known audio formats. Currently we support decoding operation only for the CPU.\n",
    "   \n",
    "   Note: Please remember, that you shall pass proper `output_type` argument to the operator. Supported types can be found in the documentation. If you have 24-bit audio data, while the audio data had 24 bit depth, it will result in loosing some information from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDecoderCpuExample(Pipeline):                   \n",
    "    def __init__(self, batch_size, num_threads, device_id):\n",
    "        super(AudioDecoderCpuExample, self).__init__(batch_size, num_threads, device_id)\n",
    "        self.input = ops.FileReader(device=\"cpu\", file_root=audio_files)\n",
    "        self.decode = ops.AudioDecoder(device=\"cpu\")\n",
    "\n",
    "    def define_graph(self):                                                                \n",
    "        read, _ = self.input()\n",
    "        audio = self.decode(read)\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now let's just build and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nvidia.dali.ops' has no attribute 'AudioDecoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-54fd11a8bd17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipecpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioDecoderCpuExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpipecpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcpu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipecpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ffa3c638472>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, num_threads, device_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAudioDecoderCpuExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefine_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nvidia.dali.ops' has no attribute 'AudioDecoder'"
     ]
    }
   ],
   "source": [
    "pipecpu = AudioDecoderCpuExample(batch_size=batch_size, num_threads=1, device_id=0)\n",
    "pipecpu.build()          \n",
    "cpu_output = pipecpu.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs from `AudioDecoder` consist of a tensor with decoded data, as well as metadata (e.g. sampling rate). To access them just check another output. Here's how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = cpu_output[0].at(0)\n",
    "sampling_rate = cpu_output[1].at(0)[0]\n",
    "print(\"Sampling rate:\", sampling_rate, \"[Hz]\")\n",
    "plt.plot(audio_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Let's verify, that the AudioDecoder actually works. The presented method can also come in handy for debugging DALI pipeline, in case something doesn't go as planned. \n",
    "\n",
    "We will use external tool to decode used data and compare the results against data decoded by DALI.\n",
    "\n",
    "### Important!\n",
    "\n",
    "Following snippet installs the external dependency (`simpleaudio`). In case you already have it, or don't want to install it, you might want to stop here and not run this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install simpleaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the side-by-side comparision of decoded data. If you have the `simpleaudio` module installed, you can run the snippet and see it for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "\n",
    "wav = sa.WaveObject.from_wave_file(\"audio/wav/three.wav\")\n",
    "three_audio = np.frombuffer(wav.audio_data, dtype=np.int16)\n",
    "\n",
    "print(\"src: simpleaudio\")\n",
    "print(\"shape: \", three_audio.shape)\n",
    "print(\"data: \", three_audio)\n",
    "print(\"\\n\")\n",
    "print(\"src: DALI\")\n",
    "print(\"shape: \", audio_data[0].shape)\n",
    "print(\"data: \", audio_data[0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(three_audio)\n",
    "ax[1].plot(audio_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "completed-input",
   "metadata": {},
   "source": [
    "### The code runs in a [NGC](https://ngc.nvidia.com/catalog/containers/nvidia:pytorch) container nvcr.io/nvidia/pytorch:21.02-py3\n",
    " - Python 3.8\n",
    " - NVIDIA CUDA 11.2.0\n",
    " - DALI 0.29.0\n",
    " - PyTorch 1.8.0a0+52ea372\n",
    " - Catalyst 21.9\n",
    "\n",
    "### To get MNIST data need to use [DALI extra](https://github.com/NVIDIA/DALI_extra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "backed-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali as dali\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator, LastBatchPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.29.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dali.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-causing",
   "metadata": {},
   "source": [
    "### To get test data you need to use [DALI extra](https://github.com/NVIDIA/DALI_extra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "creative-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "data_paths = {\n",
    "    'train': 'DALI_extra/db/MNIST/training/',\n",
    "    'valid': 'DALI_extra/db/MNIST/testing/',\n",
    "}\n",
    "\n",
    "class MNISTPipeline(Pipeline):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'train',\n",
    "        batch_size: int = 16,\n",
    "        num_threads: int = 4,\n",
    "        device_id: int = 0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_threads,\n",
    "            device_id=device_id\n",
    "        )\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.input = ops.Caffe2Reader(path=data_paths[mode], random_shuffle=True, name='Reader')\n",
    "        self.decode = ops.ImageDecoder(device = 'mixed', output_type = types.GRAY)\n",
    "        self.cmn = ops.CropMirrorNormalize(\n",
    "            device=\"gpu\",\n",
    "            dtype=types.FLOAT,\n",
    "            std=[0.3081 * 255],\n",
    "            mean=[0.1307 * 255],\n",
    "            output_layout=types.NCHW,\n",
    "        )\n",
    "    \n",
    "    def define_graph(self):\n",
    "        jpegs, labels = self.input()\n",
    "        images = self.decode(jpegs)\n",
    "        images = self.cmn(images)\n",
    "        return images, labels.gpu()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 60000 if self.mode == 'train' else 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing DALI loader for using in catalyst.\n",
    "class DALILoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'train',\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.pipeline = MNISTPipeline(mode=mode, batch_size=batch_size, num_threads=num_workers)\n",
    "        self.pipeline.build()\n",
    "        \n",
    "        self.loader = DALIGenericIterator(\n",
    "            pipelines=self.pipeline,\n",
    "            output_map=['features', 'targets'],\n",
    "            size=len(self.pipeline),\n",
    "            auto_reset=True,\n",
    "            last_batch_policy=LastBatchPolicy.PARTIAL,\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return ({'features': batch[0][\"features\"], 'targets': batch[0][\"targets\"].squeeze().long()} for batch in self.loader)\n",
    "    \n",
    "    def sampler(self):\n",
    "        return None\n",
    "    \n",
    "    def batch_sampler(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from catalyst import dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "leading-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "  _iterator_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "loaders = {\n",
    "    'train': DALILoader(mode='train', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS),\n",
    "    'valid': DALILoader(mode='valid', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boolean-directive",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43598284db874ee19d456241265e6b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='1/1 * Epoch (train)'), FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (1/1) accuracy: 0.8583166666666664 | accuracy/std: 0.07269646003630853 | accuracy01: 0.8583166666666664 | accuracy01/std: 0.07269646003630853 | accuracy03: 0.9703833333333339 | accuracy03/std: 0.03967923633655473 | accuracy05: 0.9909833333333333 | accuracy05/std: 0.023284034401133934 | loss: 1.2825655004053673 | loss/mean: 1.2825655004053673 | loss/std: 0.8768621207409731 | lr: 0.02 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17167756f01c424eb73454333c74674a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='1/1 * Epoch (valid)'), FloatProgress(value=0.0, max=313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "valid (1/1) accuracy: 0.8774 | accuracy/std: 0.058236192744843304 | accuracy01: 0.8774 | accuracy01/std: 0.058236192744843304 | accuracy03: 0.9776999999999999 | accuracy03/std: 0.024867586124993495 | accuracy05: 0.9943999999999998 | accuracy05/std: 0.012243569352890922 | loss: 1.3684241206318133 | loss/mean: 1.3684241206318133 | loss/std: 0.8965518830115483 | lr: 0.02 | momentum: 0.9\n",
      "* Epoch (1/1) \n",
      "Top best models:\n",
      "logs/checkpoints/train.1.pth\t1.3684\n"
     ]
    }
   ],
   "source": [
    "runner = dl.SupervisedRunner()\n",
    "\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=1,\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", num_classes=10),\n",
    "#         dl.PrecisionRecallF1SupportCallback(\n",
    "#             input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "#         ),\n",
    "#         dl.AUCCallback(input_key=\"logits\", target_key=\"targets\"),\n",
    "#         # catalyst[ml] required ``pip install catalyst[ml]``\n",
    "#         dl.ConfusionMatrixCallback(\n",
    "#             input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "#         ),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

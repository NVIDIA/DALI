{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DALI in PyTorch\n",
    "\n",
    "### Overview\n",
    "\n",
    "This example shows how to use DALI in PyTorch.\n",
    "\n",
    "This example uses CaffeReader.\n",
    "See other [examples](../../index.rst) for details on how to use different data formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start from defining some global constants\n",
    "\n",
    "`DALI_EXTRA_PATH` environment variable should point to the place where data from [DALI extra repository](https://github.com/NVIDIA/DALI_extra) is downloaded. Please make sure that the proper release tag is checked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "test_data_root = os.environ['DALI_EXTRA_PATH']\n",
    "\n",
    "# Caffe LMDB\n",
    "lmdb_folder = os.path.join(test_data_root, 'db', 'lmdb')\n",
    "\n",
    "N = 8             # number of GPUs\n",
    "BATCH_SIZE = 128  # batch size per GPU\n",
    "ITERATIONS = 32\n",
    "IMAGE_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a pipeline with a reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "class CaffeReadPipeline(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id, num_gpus):\n",
    "        super(CaffeReadPipeline, self).__init__(batch_size, num_threads, device_id)\n",
    "\n",
    "        self.input = ops.CaffeReader(path = lmdb_folder,\n",
    "                                     random_shuffle = True, shard_id = device_id, num_shards = num_gpus)\n",
    "        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n",
    "        self.resize = ops.Resize(device = \"gpu\",\n",
    "                                 image_type = types.RGB,\n",
    "                                 interp_type = types.INTERP_LINEAR)\n",
    "        self.cmn = ops.CropMirrorNormalize(device = \"gpu\",\n",
    "                                            output_dtype = types.FLOAT,\n",
    "                                            crop = (227, 227),\n",
    "                                            image_type = types.RGB,\n",
    "                                            mean = [128., 128., 128.],\n",
    "                                            std = [1., 1., 1.])\n",
    "        self.uniform = ops.Uniform(range = (0.0, 1.0))\n",
    "        self.resize_rng = ops.Uniform(range = (256, 480))\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.input(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        images = self.resize(images, resize_shorter = self.resize_rng())\n",
    "        output = self.cmn(images, crop_pos_x = self.uniform(),\n",
    "                          crop_pos_y = self.uniform())\n",
    "        return (output, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the pipeline and pass it to PyTorch generic iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "label_range = (0, 999)\n",
    "pipes = [CaffeReadPipeline(batch_size=BATCH_SIZE, num_threads=2, device_id = device_id, num_gpus = N) for device_id in range(N)]\n",
    "pipes[0].build()\n",
    "dali_iter = DALIGenericIterator(pipes, ['data', 'label'], pipes[0].epoch_size(\"Reader\"))\n",
    "for i, data in enumerate(dali_iter):\n",
    "    if i >= ITERATIONS:\n",
    "        break\n",
    "    # Testing correctness of labels\n",
    "    for d in data:\n",
    "        label = d[\"label\"]\n",
    "        image = d[\"data\"]\n",
    "        ## labels need to be integers\n",
    "        assert(np.equal(np.mod(label, 1), 0).all())\n",
    "        ## labels need to be in range pipe_name[2]\n",
    "        assert((label >= label_range[0]).all())\n",
    "        assert((label <= label_range[1]).all())\n",
    "print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

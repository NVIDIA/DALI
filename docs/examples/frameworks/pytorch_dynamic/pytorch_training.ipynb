{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network with DALI and TorchData\n",
    "\n",
    "This notebook trains and validates a simple classifier on MNIST,\n",
    "using DALI in dynamic mode with `torchdata.nodes` for data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import nvidia.dali.experimental.dynamic as ndd\n",
    "import nvidia.dali.types as types\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchdata.nodes as tn\n",
    "\n",
    "mnist_root = Path(os.environ[\"DALI_EXTRA_PATH\"]) / \"db\" / \"MNIST\"\n",
    "data_train = mnist_root / \"training\"\n",
    "data_test = mnist_root / \"testing\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "We decode grayscale images on the GPU and normalize them using the standard\n",
    "MNIST mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(jpegs: ndd.Batch) -> ndd.Batch:\n",
    "    images = ndd.decoders.image(jpegs, device=\"gpu\", output_type=types.GRAY)\n",
    "    images = ndd.crop_mirror_normalize(\n",
    "        images,\n",
    "        dtype=types.FLOAT,\n",
    "        output_layout=\"CHW\",\n",
    "        mean=[0.1307 * 255],\n",
    "        std=[0.3081 * 255],\n",
    "    )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader Pipeline\n",
    "\n",
    "The data loading pipeline composes dynamic mode nodes with `torchdata.nodes`:\n",
    "\n",
    "1. **Reader** reads batches from an LMDB dataset.\n",
    "2. **DictMapper** applies our `process_images` function to the `\"data\"` key.\n",
    "3. **ToTorch** converts DALI batches to PyTorch tensors, moving CPU data to GPU if necessary.\n",
    "4. **Prefetcher** overlaps data loading with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loader(data_path: Path, batch_size: int, random_shuffle: bool = True):\n",
    "    reader_node = ndd.pytorch.nodes.Reader(\n",
    "        ndd.readers.Caffe2,\n",
    "        batch_size=batch_size,\n",
    "        path=data_path,\n",
    "        random_shuffle=random_shuffle,\n",
    "    )\n",
    "    mapper_node = ndd.pytorch.nodes.DictMapper(\n",
    "        source=reader_node,\n",
    "        map_fn=process_images,\n",
    "    )\n",
    "    torch_node = ndd.pytorch.nodes.ToTorch(mapper_node)\n",
    "    prefetch_node = tn.Prefetcher(torch_node, prefetch_factor=2)\n",
    "    return tn.Loader(prefetch_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "A simple fully-connected network for 28×28 grayscale images, classifying into 10 digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = MNISTClassifier().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the model for a few epochs and report loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 — Loss: 0.2596, Accuracy: 92.5%\n",
      "Epoch 2/5 — Loss: 0.1115, Accuracy: 96.6%\n",
      "Epoch 3/5 — Loss: 0.0767, Accuracy: 97.7%\n",
      "Epoch 4/5 — Loss: 0.0577, Accuracy: 98.2%\n",
      "Epoch 5/5 — Loss: 0.0453, Accuracy: 98.6%\n"
     ]
    }
   ],
   "source": [
    "train_loader = build_loader(data_train, BATCH_SIZE, random_shuffle=True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        labels = labels.squeeze(-1).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        correct += (output.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS} — \"\n",
    "        f\"Loss: {total_loss / total:.4f}, \"\n",
    "        f\"Accuracy: {correct / total:.1%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 97.6%\n"
     ]
    }
   ],
   "source": [
    "val_loader = build_loader(data_test, BATCH_SIZE, random_shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        labels = labels.squeeze(-1).long()\n",
    "        output = model(images)\n",
    "        correct += (output.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Validation Accuracy: {100.0 * correct / total:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

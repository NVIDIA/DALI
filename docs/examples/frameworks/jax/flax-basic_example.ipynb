{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural network with DALI and Flax\n",
    "\n",
    "This simple example shows how to train a neural network implemented in Flax with DALI pipelines. If you want to learn more about training neural networks with Flax, look into [Flax Getting Started](https://flax.readthedocs.io/en/latest/getting_started.html) example.\n",
    "\n",
    "DALI setup is very similar to the [training example with pure JAX](jax-basic_example.ipynb). The only difference is the addition of a trailing dimension to the returned image to make it compatible with Flax convolutions. If you are familiar with how to use DALI with JAX you can skip this part and move to the training section of this notebook.\n",
    "\n",
    "We will use MNIST in Caffe2 format from [DALI_extra](https://github.com/NVIDIA/DALI_extra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:41.850101Z",
     "iopub.status.busy": "2023-07-28T07:43:41.849672Z",
     "iopub.status.idle": "2023-07-28T07:43:41.853520Z",
     "shell.execute_reply": "2023-07-28T07:43:41.852990Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "training_data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/training/')\n",
    "validation_data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/testing/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create a pipeline definition function that will later be used to create instances of DALI pipelines. It defines all steps of the preprocessing. In this simple example we have `fn.readers.caffe2` for reading data in Caffe2 format, `fn.decoders.image` for image decoding, `fn.crop_mirror_normalize` used to normalize the images and `fn.reshape` to adjust the shape of the output tensors. We also move the labels from the CPU to the GPU memory with `labels.gpu()` and apply one hot encoding to them for training with `fn.one_hot`.\n",
    "\n",
    "This example focuses on how to use DALI pipeline with JAX. For more information on DALI pipeline look into [Getting started](../../getting_started.ipynb) and [pipeline documentation](../../../pipeline.rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:41.855441Z",
     "iopub.status.busy": "2023-07-28T07:43:41.855301Z",
     "iopub.status.idle": "2023-07-28T07:43:41.986406Z",
     "shell.execute_reply": "2023-07-28T07:43:41.985500Z"
    }
   },
   "outputs": [],
   "source": [
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "@pipeline_def(device_id=0, batch_size=batch_size, num_threads=4, seed=0)\n",
    "def mnist_pipeline(data_path, random_shuffle):\n",
    "    jpegs, labels = fn.readers.caffe2(\n",
    "        path=data_path,\n",
    "        random_shuffle=random_shuffle,\n",
    "        name=\"mnist_caffe2_reader\")\n",
    "    images = fn.decoders.image(\n",
    "        jpegs, device='mixed', output_type=types.GRAY)\n",
    "    images = fn.crop_mirror_normalize(\n",
    "        images, dtype=types.FLOAT, std=[255.])\n",
    "    images = fn.reshape(images, shape=[-1])  # Flatten the output image\n",
    "\n",
    "    labels = labels.gpu()\n",
    "\n",
    "    if random_shuffle:\n",
    "        labels = fn.one_hot(labels, num_classes=num_classes)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to instantiate DALI pipelines and build them. Building creates and initializes pipeline internals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:41.989183Z",
     "iopub.status.busy": "2023-07-28T07:43:41.988964Z",
     "iopub.status.idle": "2023-07-28T07:43:42.104446Z",
     "shell.execute_reply": "2023-07-28T07:43:42.103668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipelines\n",
      "<nvidia.dali.pipeline.Pipeline object at 0x7fb455793940>\n",
      "<nvidia.dali.pipeline.Pipeline object at 0x7fb455791390>\n"
     ]
    }
   ],
   "source": [
    "training_pipeline = mnist_pipeline(data_path=training_data_path, random_shuffle=True)\n",
    "validation_pipeline = mnist_pipeline(data_path=validation_data_path, random_shuffle=False)\n",
    "\n",
    "print('Building pipelines')\n",
    "training_pipeline.build()\n",
    "validation_pipeline.build()\n",
    "\n",
    "print(training_pipeline)\n",
    "print(validation_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DALI pipeline needs to be wrapped with appropriate DALI iterator to work with JAX. To get the iterator compatible with JAX we need to import it from DALI JAX plugin. In addition to the DALI pipeline object we can pass the `output_map`, `reader_name` and `auto_reset` parameters to the iterator. \n",
    "\n",
    "**Here is a quick explnation of how these parameters work:**\n",
    "\n",
    " - `output_map`: iterators return a dictionary with outputs of the pipeline as its values. Keys in this dictionary are defined by `output_map`. For example, `labels` output returned from the DALI pipeline defined above will be accessible as `iterator_output['labels']`,\n",
    " - `reader_name`: setting this parameter introduces the notion of an epoch to our iterator. DALI pipeline itself is infinite, it will return the data indefinately, wrapping around the dataset. DALI readers (such as `fn.readers.caffe2` used in this example) have access to the information about the size of the dataset. If we want to pass this information to the iterator, we need to point to the operator that should be queried for the dataset size. We do it by naming the operator (note `name=\"mnist_caffe2_reader\"`) and passing the same name as the value for `reader_name` argument,\n",
    "  - `auto_reset`: this argument controls the behaviour of the iterator after the end of an epoch. If set to `True`, it will automatically reset the state of the iterator and prepare it to start the next epoch.\n",
    "\n",
    "If you want to know more about iterator arguments you can look into [JAX iterator documentation](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/plugins/jax_plugin_api.html#nvidia.dali.plugin.jax.DALIGenericIterator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:42.109692Z",
     "iopub.status.busy": "2023-07-28T07:43:42.109536Z",
     "iopub.status.idle": "2023-07-28T07:43:43.557199Z",
     "shell.execute_reply": "2023-07-28T07:43:43.556686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating iterators\n",
      "<nvidia.dali.plugin.jax.DALIGenericIterator object at 0x7fb450301b70>\n",
      "Number of batches in training iterator = 300\n",
      "Number of batches in validation iterator = 50\n"
     ]
    }
   ],
   "source": [
    "from nvidia.dali.plugin import jax as dax\n",
    "\n",
    "\n",
    "print('Creating iterators')\n",
    "training_iterator = dax.DALIGenericIterator(\n",
    "    training_pipeline,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True)\n",
    "\n",
    "validation_iterator = dax.DALIGenericIterator(\n",
    "    validation_pipeline,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True)\n",
    "\n",
    "print(training_iterator)\n",
    "print(f\"Number of batches in training iterator = {len(training_iterator)}\")\n",
    "print(f\"Number of batches in validation iterator = {len(validation_iterator)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the setup above, DALI iterators are ready for the training. \n",
    "\n",
    "Now we need to setup model and training utilities. The goal of this notebook is not to explain Flax concepts. We want to show how to train models implemented in Flax with DALI as a data loading and preprocessing library. We used standard Flax tools do define simple neural network. We have functions to create an instance of this network, run one training step on it and calculate accuracy of the model at the end of each epoch.\n",
    "\n",
    "If you want to learn more about Flax and get better understanding of the code below, look into [Flax Documentation](https://flax.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:43.559575Z",
     "iopub.status.busy": "2023-07-28T07:43:43.559420Z",
     "iopub.status.idle": "2023-07-28T07:43:43.618221Z",
     "shell.execute_reply": "2023-07-28T07:43:43.617532Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=784)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_model_state(rng, learning_rate, momentum):\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([784]))['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=cnn.apply, params=params, tx=tx)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(model_state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = model_state.apply_fn({'params': params}, batch['images'])\n",
    "        loss = optax.softmax_cross_entropy(logits=logits, labels=batch['labels']).mean()\n",
    "        return loss\n",
    "    grad_fn = jax.grad(loss_fn)\n",
    "    grads = grad_fn(model_state.params)\n",
    "    model_state = model_state.apply_gradients(grads=grads)\n",
    "    return model_state\n",
    "\n",
    "\n",
    "def accuracy(model_state, iterator):\n",
    "    correct_predictions = 0\n",
    "    for batch in iterator:\n",
    "        logits = model_state.apply_fn({'params': model_state.params}, batch['images'])\n",
    "        correct_predictions = correct_predictions + \\\n",
    "            jnp.sum(batch['labels'].ravel() == jnp.argmax(logits, axis=-1))\n",
    "\n",
    "    return correct_predictions / iterator.size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With utilities defined above, we can create an instance of the model we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:43.622376Z",
     "iopub.status.busy": "2023-07-28T07:43:43.621205Z",
     "iopub.status.idle": "2023-07-28T07:43:58.016073Z",
     "shell.execute_reply": "2023-07-28T07:43:58.015333Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "model_state = create_model_state(init_rng, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, everything is ready to run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 0\n",
      "Accuracy = 0.9637000560760498\n",
      "Epoch 1\n",
      "Accuracy = 0.9690000414848328\n",
      "Epoch 2\n",
      "Accuracy = 0.975100040435791\n",
      "Epoch 3\n",
      "Accuracy = 0.9761000275611877\n",
      "Epoch 4\n",
      "Accuracy = 0.9765000343322754\n"
     ]
    }
   ],
   "source": [
    "print('Starting training')\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for batch in training_iterator:\n",
    "        model_state = train_step(model_state, batch)\n",
    "\n",
    "    acc = accuracy(model_state, validation_iterator)\n",
    "    print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple GPUs with DALI and FLAX\n",
    "\n",
    "This section shows how to extend the example above to use multiple GPUs.\n",
    "\n",
    "Again, we start with creating a pipeline definition function. The pipeline was slightly modified to support multiple GPUs.\n",
    "\n",
    "Note the new arguments passed to `fn.readers.caffe2`: `num_shards` and `shard_id`. They are used to control sharding:\n",
    " - `num_shards` sets the total number of shards\n",
    " - `shard_id` tells the pipeline for which shard in the training it is responsible. \n",
    "\n",
    " Also, the `device_id` argument was removed from the decorator. Since we want these pipelines to run on different GPUs we will pass particular `device_id` in pipeline creation. Most often, `device_id` and `shard_id` will have the same value but it is not a requirement. In this example we want the total batch size to be the same as in the single GPU version. That is why we define `batch_size_per_gpu` as `batch_size // jax.device_count()`. Note, that if `batch_size` is not divisible by the number of devices this might require some adjustment to make sure all samples are used in every epoch of the training.\n",
    " If you want to learn more about DALI sharding behaviour look into [DALI sharding docs page](../../general/multigpu.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "batch_size_per_gpu = batch_size // jax.device_count()\n",
    "\n",
    "\n",
    "@pipeline_def(batch_size=batch_size_per_gpu, num_threads=4, seed=0)\n",
    "def mnist_sharded_pipeline(data_path, random_shuffle, num_shards, shard_id):\n",
    "    jpegs, labels = fn.readers.caffe2(\n",
    "        path=data_path,\n",
    "        random_shuffle=random_shuffle,\n",
    "        name=\"mnist_caffe2_reader\",\n",
    "        num_shards=num_shards,\n",
    "        shard_id=shard_id)\n",
    "    images = fn.decoders.image(\n",
    "        jpegs, device='mixed', output_type=types.GRAY)\n",
    "    images = fn.crop_mirror_normalize(\n",
    "        images, dtype=types.FLOAT, std=[255.], output_layout=\"CHW\")\n",
    "    images = fn.reshape(images, shape=[-1])  # Flatten the output image\n",
    "\n",
    "    labels = labels.gpu()\n",
    "    \n",
    "    if random_shuffle:\n",
    "        labels = fn.one_hot(labels, num_classes=num_classes)\n",
    "\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `device_id` values that are passed to place a pipeline on a different device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline <nvidia.dali.pipeline.Pipeline object at 0x7db28c2b2da0> working on device 0\n",
      "Pipeline <nvidia.dali.pipeline.Pipeline object at 0x7db28c2b30d0> working on device 1\n"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "for id, device in enumerate(jax.devices()):\n",
    "    pipeline = mnist_sharded_pipeline(\n",
    "        data_path=training_data_path, random_shuffle=True, num_shards=jax.device_count(), shard_id=id, device_id=id)\n",
    "    print(f'Pipeline {pipeline} working on device {pipeline.device_id}')\n",
    "    pipelines.append(pipeline)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created multiple DALI pipelines. Each will run its computations on a different GPU. Each of them will start the preprocessing from a different shard of the training dataset. In this configuration each pipeline will move to the next shard in the next epoch. If you want to control this you can look into `stick_to_shard` argument in the readers.\n",
    "\n",
    "Like in the single GPU example, we create training iterator. It will encapsulate all the pipelines that we created and return a dictionary of JAX arrays. With this simple configuration it will return arrays compatible with JAX `pmap`ed functions. Leaves of the returned dictionary will have shape `(num_devices, batch_per_device, ...)` and each slice across the first dimension of the array will reside on a different GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training iterator\n",
      "Number of batches in training iterator = 300\n"
     ]
    }
   ],
   "source": [
    "print('Creating training iterator')\n",
    "training_iterator = dax.DALIGenericIterator(\n",
    "    pipelines,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True)\n",
    "\n",
    "print(f\"Number of batches in training iterator = {len(training_iterator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will run validation on one GPU. We can reuse the validation iterator from the single GPU example. The only difference is that we will need to pull the model to the same GPU. In real life scenario this might be costly but for this toy educational example is suficient. \n",
    "\n",
    "\n",
    "For the model to be compatible with pmap-style multiple GPU training we need to replicate it. If you want to learn more about training on multiple GPUs with `pmap` you can look into [Parallel Evaluation in JAX](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html) from the JAX documentation and [Ensembling on multiple devices](https://flax.readthedocs.io/en/latest/guides/ensembling.html#ensembling-on-multiple-devices) from Flax documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "model_state = jax.pmap(\n",
    "    create_model_state,\n",
    "    static_broadcasted_argnums=(1, 2))(\n",
    "        jax.random.split(\n",
    "            init_rng,\n",
    "            jax.device_count()),\n",
    "        learning_rate,\n",
    "        momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to run validation on single GPU, we extract only one replica of the model and pass it to `accuracy` function. \n",
    "\n",
    "Now, we are ready to train Flax model on multiple GPUs with DALI as the data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Accuracy = 0.9445000290870667\n",
      "Epoch 1\n",
      "Accuracy = 0.9641000628471375\n",
      "Epoch 2\n",
      "Accuracy = 0.9654000401496887\n",
      "Epoch 3\n",
      "Accuracy = 0.9724000692367554\n",
      "Epoch 4\n",
      "Accuracy = 0.9760000705718994\n"
     ]
    }
   ],
   "source": [
    "import flax\n",
    "\n",
    "parallel_train_step = jax.pmap(train_step)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for batch in training_iterator:\n",
    "        model_state = parallel_train_step(model_state, batch)\n",
    "\n",
    "    acc = accuracy(\n",
    "        flax.jax_utils.unreplicate(model_state),\n",
    "        validation_iterator)\n",
    "    print(f\"Accuracy = {acc}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

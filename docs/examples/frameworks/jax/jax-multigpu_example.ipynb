{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with multiple GPUs\n",
    "\n",
    "Here we show how to run training from [\"Training neural network with DALI and JAX\"](jax-basic_example.ipynb) on multiple GPUs. If you haven't already done so it is best to start with single GPU example to better understand following content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Again, we start with creating a pipeline definition function. For the future multiple GPU support it was slightly modified from the single GPU version.\n",
    "\n",
    "Note the new arguments passed to `fn.readers.caffe2`: `num_shards` and `shard_id`. They are used to control sharding:\n",
    " - `num_shards` sets the total number of shards\n",
    " - `shard_id` tells the pipeline for which shard in the training it is responsible. \n",
    "\n",
    " Also, the `device_id` argument was removed from the decorator. Since we want these pipelines run on different GPUs we will pass particular `device_id` in pipeline creation. Most often, `device_id` and `shard_id` will have the same value but it is not a requirement. In this example we want the total batch size to be the same as in the single GPU version. That is why we define `batch_size_per_gpu` as `batch_size // jax.device_cout()`. Note, that if `batch_size` is not divisible by the number of devices this might require some adjustment to make sure all samples are used in every epoch of the training.\n",
    " If you want to learn more about DALI sharding behaviour look into [DALI sharding docs page](../../general/multigpu.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:58.022258Z",
     "iopub.status.busy": "2023-07-28T07:43:58.021951Z",
     "iopub.status.idle": "2023-07-28T07:43:58.025225Z",
     "shell.execute_reply": "2023-07-28T07:43:58.024884Z"
    }
   },
   "outputs": [],
   "source": [
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import jax\n",
    "import os\n",
    "\n",
    "\n",
    "training_data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/training/')\n",
    "validation_data_path = os.path.join(os.environ['DALI_EXTRA_PATH'], 'db/MNIST/testing/')\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "batch_size_per_gpu = batch_size // jax.device_count()\n",
    "\n",
    "\n",
    "@pipeline_def(batch_size=batch_size_per_gpu, num_threads=4, seed=0)\n",
    "def mnist_sharded_pipeline(data_path, random_shuffle, num_shards, shard_id):\n",
    "    jpegs, labels = fn.readers.caffe2(\n",
    "        path=data_path,\n",
    "        random_shuffle=random_shuffle,\n",
    "        name=\"mnist_caffe2_reader\",\n",
    "        num_shards=num_shards,\n",
    "        shard_id=shard_id)\n",
    "    images = fn.decoders.image(\n",
    "        jpegs, device='mixed', output_type=types.GRAY)\n",
    "    images = fn.crop_mirror_normalize(\n",
    "        images, dtype=types.FLOAT, std=[255.], output_layout=\"CHW\")\n",
    "    images = fn.reshape(images, shape=[image_size * image_size])\n",
    "\n",
    "    labels = labels.gpu()\n",
    "    \n",
    "    if random_shuffle:\n",
    "        labels = fn.one_hot(labels, num_classes=num_classes)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `device_id` values that are passed to place a pipeline on a different device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:58.027039Z",
     "iopub.status.busy": "2023-07-28T07:43:58.026762Z",
     "iopub.status.idle": "2023-07-28T07:43:58.242130Z",
     "shell.execute_reply": "2023-07-28T07:43:58.240945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training pipelines\n",
      "Pipeline <nvidia.dali.pipeline.Pipeline object at 0x7fcb5429ec20> working on device 0\n",
      "Pipeline <nvidia.dali.pipeline.Pipeline object at 0x7fcb5429e800> working on device 1\n"
     ]
    }
   ],
   "source": [
    "from nvidia.dali.plugin import jax as dax\n",
    "\n",
    "print('Creating training pipelines')\n",
    "\n",
    "pipelines = []\n",
    "for id, device in enumerate(jax.devices()):\n",
    "    pipeline = mnist_sharded_pipeline(\n",
    "        data_path=training_data_path, random_shuffle=True, num_shards=jax.device_count(), shard_id=id, device_id=id)\n",
    "    print(f'Pipeline {pipeline} working on device {pipeline.device_id}')\n",
    "    pipelines.append(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created multiple DALI pipelines. Each will run its computations on a differnt GPU. Each of them will start the preprocessing from a differnt shard of the training dataset. In this configuration each pipeline will move to the next shard in the next epoch. If you want to control this you can look into `stick_to_shard` argument in the readers.\n",
    "\n",
    "Like in the single GPU example, we create training iterator. It will encapsulate all the pipelines that we created and return a dictionary of JAX arrays. With this simple configuration it will return arrays compatible with JAX `pmap`ed functions. Leaves of the returned dictionary will have shape `(num_devices, batch_per_device, ...)` and each slice across the first dimension of the array will reside on a different GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training iterator\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:61: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ has 60000 entries\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/decoder/nvjpeg/nvjpeg_decoder_decoupled_api.h:192: NVJPEG_BACKEND_HARDWARE is either disabled or not supported\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:61: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ has 60000 entries\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:91: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ exec a large step forward 0->30000\n",
      "/home/awolant/Projects/DALI/dali/operators/decoder/nvjpeg/nvjpeg_decoder_decoupled_api.h:192: NVJPEG_BACKEND_HARDWARE is either disabled or not supported\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "Number of batches in training iterator = 300\n"
     ]
    }
   ],
   "source": [
    "print('Creating training iterator')\n",
    "training_iterator = dax.DALIGenericIterator(\n",
    "    pipelines,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True)\n",
    "\n",
    "print(f\"Number of batches in training iterator = {len(training_iterator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will run validation on one GPU. We can pass `num_shards=1`, `shard_id=0` and `device_id=0` to `mnist_sharded_pipeline`. It will result in a pipeline identical as in the single GPU example and we can create the validation iterator the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation iterator\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:61: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ has 10000 entries\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/decoder/nvjpeg/nvjpeg_decoder_decoupled_api.h:192: NVJPEG_BACKEND_HARDWARE is either disabled or not supported\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Number of batches in validation iterator = 100\n"
     ]
    }
   ],
   "source": [
    "print('Creating validation iterator')\n",
    "validation_pipeline = mnist_sharded_pipeline(data_path=validation_data_path, random_shuffle=False, num_shards=1, shard_id=0, device_id=0)\n",
    "\n",
    "validation_iterator = dax.DALIGenericIterator(\n",
    "    validation_pipeline,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True)\n",
    "\n",
    "print(f\"Number of batches in validation iterator = {len(validation_iterator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model to be compatible with pmap-style multiple GPU training we need to replicate it. If you want to learn more about training on multiple GPUs with `pmap` you can look into [Parallel Evaluation in JAX](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html) from the JAX documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:58.245168Z",
     "iopub.status.busy": "2023-07-28T07:43:58.244604Z",
     "iopub.status.idle": "2023-07-28T07:43:58.292113Z",
     "shell.execute_reply": "2023-07-28T07:43:58.291012Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from model import init_model, accuracy\n",
    "\n",
    "\n",
    "model = init_model()\n",
    "model = jax.tree_map(lambda x: jnp.array([x] * jax.device_count()), model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multigpu training we import `update_parallel` function. It is the same as the `update` function with added gradients synchronization across the devices. This will ensure that replicas of the model from different devices remain the same. \n",
    "\n",
    "Since we want to run validation on single GPU, we extract only one replica of the model and pass it to `accuracy` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T07:43:58.294940Z",
     "iopub.status.busy": "2023-07-28T07:43:58.294735Z",
     "iopub.status.idle": "2023-07-28T07:44:12.533682Z",
     "shell.execute_reply": "2023-07-28T07:44:12.533238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 0 sec\n",
      "Test set accuracy 0.6728000044822693\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 1 sec\n",
      "Test set accuracy 0.7841000556945801\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 2 sec\n",
      "Test set accuracy 0.8242000341415405\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 3 sec\n",
      "Test set accuracy 0.838100016117096\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 4 sec\n",
      "Test set accuracy 0.8521000146865845\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 5 sec\n",
      "Test set accuracy 0.8714000582695007\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 6 sec\n",
      "Test set accuracy 0.8771000504493713\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 7 sec\n",
      "Test set accuracy 0.8825000524520874\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 8 sec\n",
      "Test set accuracy 0.8875000476837158\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 9 sec\n",
      "Test set accuracy 0.8835000395774841\n"
     ]
    }
   ],
   "source": [
    "from model import update_parallel\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for it, batch in enumerate(training_iterator):\n",
    "        model = update_parallel(model, batch)\n",
    "        \n",
    "    test_acc = accuracy(jax.tree_map(lambda x: x[0], model), validation_iterator)\n",
    "    \n",
    "    print(f\"Epoch {epoch} sec\")\n",
    "    print(f\"Test set accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic parallelization\n",
    "\n",
    "The following section shows how to apply automatic parallelization mechanisms in training with DALI and JAX. To learn more about these concepts look into [Distributed arrays and automatic parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) JAX tutrial.\n",
    "\n",
    "It is possible to pass `jax.sharding.Sharding` object to DALI iterator. It will be used to construct output arrays consistent with the sharding. In this example we use simple `PositionalSharding` and pass it to `dax.DALIGenericIterator` initialization. Everything else remains the same. We even used the same pipeline objects for this new iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training iterator\n",
      "Number of batches in training iterator = 300\n"
     ]
    }
   ],
   "source": [
    "from jax.sharding import PositionalSharding, Mesh\n",
    "from jax.experimental import mesh_utils\n",
    "\n",
    "\n",
    "mesh = mesh_utils.create_device_mesh((jax.device_count(), 1))\n",
    "sharding = PositionalSharding(mesh)\n",
    "\n",
    "print('Creating training iterator')\n",
    "training_iterator = dax.DALIGenericIterator(\n",
    "    pipelines,\n",
    "    output_map=[\"images\", \"labels\"],\n",
    "    reader_name=\"mnist_caffe2_reader\",\n",
    "    auto_reset=True,\n",
    "    sharding=sharding)\n",
    "\n",
    "print(f\"Number of batches in training iterator = {len(training_iterator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new iterator is ready for the training. This example utilizes automatic parallelization where the computation follows the data placement. This means that we can use the same `update` function that we used in (single GPU training example)[jax-basic_example.ipynb] and it will automatically run computations on multiple GPUs.\n",
    "\n",
    "For simplicity we use the same `validation_iterator` as before and run the `accuracy` calculation on a single GPU. Model is spread between the devices and we need to pull it to one of them for this to work. Otherwise JAX would throw an error. In real life scenarios this might not be the best for performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 0 sec\n",
      "Test set accuracy 0.6866000294685364\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 1 sec\n",
      "Test set accuracy 0.7851000428199768\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 2 sec\n",
      "Test set accuracy 0.8140000104904175\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 3 sec\n",
      "Test set accuracy 0.8414000272750854\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 4 sec\n",
      "Test set accuracy 0.8571000695228577\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 5 sec\n",
      "Test set accuracy 0.8690000176429749\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 6 sec\n",
      "Test set accuracy 0.8689000606536865\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 7 sec\n",
      "Test set accuracy 0.8828000426292419\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 8 sec\n",
      "Test set accuracy 0.8868000507354736\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 59999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/training/ rewind to the begin from 0\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 9999\n",
      "/home/awolant/Projects/DALI/dali/operators/reader/loader/lmdb.h:76: lmdb 0 /home/awolant/Projects/DALI_extra/db/MNIST/testing/ rewind to the begin from 0\n",
      "Epoch 9 sec\n",
      "Test set accuracy 0.8909000158309937\n"
     ]
    }
   ],
   "source": [
    "from model import update\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for it, batch in enumerate(training_iterator):\n",
    "        model = update(model, batch)\n",
    "        \n",
    "    model_on_one_device = jax.tree_map(lambda x: jax.device_put(x, jax.devices()[0]), model)\n",
    "    test_acc = accuracy(model_on_one_device, validation_iterator)\n",
    "    \n",
    "    print(f\"Epoch {epoch} sec\")\n",
    "    print(f\"Test set accuracy {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# DALI CLAHE (Contrast Limited Adaptive Histogram Equalization) Example\n",
    "\n",
    "This notebook demonstrates how to use **CLAHE (Contrast Limited Adaptive Histogram Equalization)** in a DALI pipeline for image preprocessing. CLAHE is a powerful technique that improves contrast in images without overamplifying noise, making it particularly useful for medical imaging, surveillance, and low-contrast photography.\n",
    "\n",
    "## What is CLAHE?\n",
    "\n",
    "CLAHE is an enhanced version of Adaptive Histogram Equalization (AHE) that:\n",
    "- âœ… **Improves local contrast** by processing image tiles independently\n",
    "- âœ… **Prevents noise amplification** through contrast limiting\n",
    "- âœ… **Preserves image quality** while enhancing details\n",
    "- âœ… **Works well on various image types** from medical scans to natural photos\n",
    "\n",
    "## Key Features of DALI's CLAHE Implementation\n",
    "\n",
    "- ğŸš€ **High Performance**: GPU-accelerated implementation\n",
    "- ğŸ”§ **Flexible Parameters**: Customizable tile sizes and clip limits\n",
    "- ğŸ¨ **Color-Aware**: Option to process luminance only for RGB images\n",
    "- ğŸ“Š **Seamless Integration**: Works within DALI pipelines\n",
    "\n",
    "**References:**\n",
    "- [Wikipedia: Adaptive Histogram Equalization](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization)\n",
    "- [OpenCV CLAHE Tutorial](https://docs.opencv.org/4.12.0/d5/daf/tutorial_py_histogram_equalization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Required Imports\n",
    "\n",
    "Let's start by importing the necessary DALI modules and NumPy for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nvidia.dali as dali\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Building the CLAHE Pipeline\n",
    "\n",
    "The main pipeline function creates a DALI processing pipeline that applies CLAHE enhancement to images. This pipeline can work with either real images from a directory or synthetic test data.\n",
    "\n",
    "### Key CLAHE Parameters:\n",
    "\n",
    "| Parameter | Description | Typical Values |\n",
    "|-----------|-------------|----------------|\n",
    "| `tiles_x`, `tiles_y` | Grid size for local processing | 4-16 (higher = more local adaptation) |\n",
    "| `clip_limit` | Threshold to prevent noise amplification | 1.0-4.0 (higher = more contrast) |\n",
    "| `luma_only` | For RGB: process only luminance channel | `True` (preserves color balance) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_clahe_pipeline(\n",
    "    batch_size=4, num_threads=2, device_id=0, image_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DALI pipeline with CLAHE operator.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Number of images per batch\n",
    "        num_threads (int): Number of worker threads\n",
    "        device_id (int): GPU device ID\n",
    "        image_dir (str): Directory containing images (if None, uses synthetic data)\n",
    "\n",
    "    Returns:\n",
    "        DALI pipeline with CLAHE preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    @dali.pipeline_def(\n",
    "        batch_size=batch_size, num_threads=num_threads, device_id=device_id\n",
    "    )\n",
    "    def clahe_preprocessing_pipeline():\n",
    "        if image_dir:\n",
    "            # Read images from directory\n",
    "            images, labels = fn.readers.file(\n",
    "                file_root=image_dir, random_shuffle=True\n",
    "            )\n",
    "            images = fn.decoders.image(images, device=\"mixed\")  # Decode on GPU\n",
    "\n",
    "            # Resize to consistent size\n",
    "            images = fn.resize(images, size=[256, 256])\n",
    "        else:\n",
    "            # Create synthetic test images with varying contrast\n",
    "            # This simulates real-world scenarios where CLAHE is beneficial\n",
    "\n",
    "            # Generate base image with moderate values to avoid overflow\n",
    "            images = fn.random.uniform(\n",
    "                range=(60, 180), shape=(256, 256, 3), dtype=types.FLOAT\n",
    "            )\n",
    "\n",
    "            # Add some contrast variation to make CLAHE effect visible\n",
    "            contrast_factor = fn.random.uniform(range=(0.5, 0.9))\n",
    "            images = images * contrast_factor\n",
    "\n",
    "            # Add small brightness variation (keeping within safe range)\n",
    "            brightness_offset = fn.random.uniform(range=(-20, 20))\n",
    "            images = images + brightness_offset\n",
    "\n",
    "            # Convert to uint8 (DALI will automatically clamp to [0,255])\n",
    "            images = fn.cast(images, dtype=types.UINT8)\n",
    "\n",
    "        # ğŸ¯ Apply CLAHE for adaptive histogram equalization\n",
    "        # This is where the magic happens!\n",
    "        clahe_images = fn.clahe(\n",
    "            images,\n",
    "            tiles_x=8,  # 8x8 grid of tiles for local processing\n",
    "            tiles_y=8,\n",
    "            clip_limit=2.0,  # Moderate clipping to prevent noise\n",
    "            luma_only=True,  # RGB: process luminance only to preserve colors\n",
    "        )\n",
    "\n",
    "        return images, clahe_images\n",
    "\n",
    "    return clahe_preprocessing_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Parameter Comparison Function\n",
    "\n",
    "Let's create a function to demonstrate how different CLAHE parameters affect the results. This will help you understand how to tune the parameters for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def demonstrate_clahe_parameters():\n",
    "    \"\"\"\n",
    "    Demonstrate different CLAHE parameter settings to show their effects.\n",
    "\n",
    "    Returns:\n",
    "        DALI pipeline that generates one base image and three CLAHE variants\n",
    "    \"\"\"\n",
    "\n",
    "    @dali.pipeline_def(batch_size=1, num_threads=1, device_id=0)\n",
    "    def parameter_demo_pipeline():\n",
    "        # Create a test image with poor contrast (narrow intensity range)\n",
    "        base_image = fn.random.uniform(\n",
    "            range=(80, 120), shape=(256, 256, 1), dtype=types.UINT8\n",
    "        )\n",
    "\n",
    "        # ğŸ”§ Different CLAHE configurations to compare:\n",
    "\n",
    "        # 1. Default settings - balanced approach\n",
    "        clahe_default = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=8,\n",
    "            tiles_y=8,  # Standard 8x8 grid\n",
    "            clip_limit=2.0,  # Moderate contrast limiting\n",
    "        )\n",
    "\n",
    "        # 2. Aggressive enhancement - more contrast, more local adaptation\n",
    "        clahe_aggressive = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=16,\n",
    "            tiles_y=16,  # Finer 16x16 grid\n",
    "            clip_limit=4.0,  # Higher contrast limit\n",
    "        )\n",
    "\n",
    "        # 3. Gentle enhancement - subtle improvement\n",
    "        clahe_gentle = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=4,\n",
    "            tiles_y=4,  # Coarser 4x4 grid\n",
    "            clip_limit=1.0,  # Conservative contrast limit\n",
    "        )\n",
    "\n",
    "        return base_image, clahe_default, clahe_aggressive, clahe_gentle\n",
    "\n",
    "    return parameter_demo_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Running the CLAHE Pipeline\n",
    "\n",
    "Now let's execute our pipeline and see CLAHE in action! We'll analyze the results and measure the contrast improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ—ï¸ Create and build pipeline\n",
    "print(\"ğŸ”§ Creating CLAHE pipeline...\")\n",
    "pipe = create_clahe_pipeline(batch_size=2, num_threads=1, device_id=0)\n",
    "pipe.build()\n",
    "print(\"âœ… Pipeline built successfully\")\n",
    "\n",
    "# ğŸ¬ Run pipeline\n",
    "print(\"\\nğŸ¬ Running pipeline...\")\n",
    "outputs = pipe.run()\n",
    "original_images, clahe_images = outputs\n",
    "\n",
    "# ğŸ“¥ Move to CPU for analysis\n",
    "original_batch = original_images.as_cpu()\n",
    "clahe_batch = clahe_images.as_cpu()\n",
    "\n",
    "print(f\"âœ… Processed {len(original_batch)} images\")\n",
    "\n",
    "# ğŸ“Š Analyze results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“Š CLAHE RESULTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(len(original_batch)):\n",
    "    original = np.array(original_batch[i])\n",
    "    enhanced = np.array(clahe_batch[i])\n",
    "\n",
    "    print(f\"\\nğŸ–¼ï¸  Image {i + 1}:\")\n",
    "    print(\n",
    "        f\"  ğŸ“ Original  - Shape: {original.shape}, Range: [{original.min():.1f}, {original.max():.1f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  âœ¨ Enhanced  - Shape: {enhanced.shape}, Range: [{enhanced.min():.1f}, {enhanced.max():.1f}]\"\n",
    "    )\n",
    "\n",
    "    # Calculate contrast metrics (standard deviation as a proxy for contrast)\n",
    "    orig_std = np.std(original)\n",
    "    enhanced_std = np.std(enhanced)\n",
    "    contrast_improvement = enhanced_std / orig_std if orig_std > 0 else 1.0\n",
    "\n",
    "    print(f\"  ğŸ“ˆ Contrast improvement: {contrast_improvement:.2f}x\")\n",
    "\n",
    "print(\"\\nğŸ‰ CLAHE pipeline executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Parameter Comparison Experiment\n",
    "\n",
    "Let's compare different CLAHE parameter settings to understand their effects on image enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¬ Demonstrate parameter variations\n",
    "print(\"ğŸ”¬ Testing different CLAHE parameters...\")\n",
    "param_pipe = demonstrate_clahe_parameters()\n",
    "param_pipe.build()\n",
    "\n",
    "param_outputs = param_pipe.run()\n",
    "base, default, aggressive, gentle = param_outputs\n",
    "\n",
    "# Convert to numpy arrays for analysis\n",
    "base_img = np.array(base.as_cpu()[0])\n",
    "default_img = np.array(default.as_cpu()[0])\n",
    "aggressive_img = np.array(aggressive.as_cpu()[0])\n",
    "gentle_img = np.array(gentle.as_cpu()[0])\n",
    "\n",
    "# ğŸ“Š Compare the results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ›ï¸  PARAMETER COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configurations = [\n",
    "    (\"ğŸ”¸ Base image (no CLAHE)\", base_img),\n",
    "    (\"âš–ï¸  Default CLAHE (8x8, limit=2.0)\", default_img),\n",
    "    (\"ğŸ”¥ Aggressive CLAHE (16x16, limit=4.0)\", aggressive_img),\n",
    "    (\"ğŸŒ¸ Gentle CLAHE (4x4, limit=1.0)\", gentle_img),\n",
    "]\n",
    "\n",
    "for name, img in configurations:\n",
    "    std_dev = np.std(img)\n",
    "    print(f\"{name}\")\n",
    "    print(f\"   ğŸ“Š Standard deviation (contrast measure): {std_dev:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"ğŸ’¡ Key Takeaways:\")\n",
    "print(\"   â€¢ Higher std dev = more contrast\")\n",
    "print(\"   â€¢ More tiles (16x16) = more local adaptation\")\n",
    "print(\"   â€¢ Higher clip limit = stronger enhancement\")\n",
    "print(\"   â€¢ Choose parameters based on your image type and requirements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Practical Applications & Next Steps\n",
    "\n",
    "### Where to Use CLAHE:\n",
    "- ğŸ¥ **Medical Imaging**: Enhance X-rays, CT scans, MRI images\n",
    "- ğŸ‘ï¸ **Computer Vision**: Improve object detection in low-contrast scenes  \n",
    "- ğŸ“¸ **Photography**: Enhance details in shadows and highlights\n",
    "- ğŸ›¡ï¸ **Security**: Improve visibility in surveillance footage\n",
    "- ğŸŒŒ **Astronomy**: Enhance celestial object visibility\n",
    "\n",
    "### Parameter Tuning Guidelines:\n",
    "\n",
    "| Image Type | Recommended tiles_x/y | Recommended clip_limit | Notes |\n",
    "|------------|----------------------|----------------------|-------|\n",
    "| Medical scans | 8-12 | 1.5-2.5 | Preserve diagnostic details |\n",
    "| Natural photos | 6-10 | 2.0-3.0 | Balance enhancement and naturalness |\n",
    "| Low-light images | 10-16 | 3.0-4.0 | Aggressive enhancement acceptable |\n",
    "| High-noise images | 4-8 | 1.0-2.0 | Avoid amplifying noise |\n",
    "\n",
    "### Performance Tips:\n",
    "- ğŸš€ Use `device=\"gpu\"` for maximum performance\n",
    "- ğŸ“¦ Process images in batches when possible\n",
    "- ğŸ¨ Set `luma_only=True` for RGB images to preserve color balance\n",
    "- ğŸ”§ Experiment with parameters on representative samples\n",
    "\n",
    "### Try These Experiments:\n",
    "1. **Real Images**: Replace synthetic data with your own image directory\n",
    "2. **Video Processing**: Apply CLAHE to video frames in a sequence\n",
    "3. **Multi-scale Enhancement**: Combine CLAHE with other DALI operators\n",
    "4. **Benchmarking**: Compare CLAHE performance vs. other enhancement methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLAHE Tutorial with NVIDIA DALI\n",
    "Welcome to this hands-on tutorial!\n",
    "In this notebook, you'll learn how to use Contrast Limited Adaptive Histogram Equalization (CLAHE) with NVIDIA DALI for image enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction to CLAHE\n",
    "This notebook demonstrates how to use **CLAHE (Contrast Limited Adaptive Histogram Equalization)** in a DALI pipeline for image preprocessing.\n",
    "\n",
    "CLAHE is a powerful technique that improves contrast in images without overamplifying noise, making it particularly useful for medical imaging, surveillance, and low-contrast photography.\n",
    "\n",
    "## Using Real Medical Imaging Data\n",
    "This tutorial includes demonstrations with **real knee MRI slices** from the DALI_extra repository, which perfectly showcase CLAHE's effectiveness on low-contrast medical images.\n",
    "\n",
    "**To use the MRI data:**\n",
    "```bash\n",
    "# Clone DALI_extra (requires git-lfs)\n",
    "git clone https://github.com/NVIDIA/DALI_extra.git\n",
    "cd DALI_extra && git lfs pull\n",
    "\n",
    "# Set environment variable\n",
    "export DALI_EXTRA_PATH=/path/to/DALI_extra\n",
    "```\n",
    "\n",
    "The MRI data will be at: `$DALI_EXTRA_PATH/db/3D/MRI/Knee/npy_2d_slices/STU00001/SER00001/`\n",
    "\n",
    "The data is organized in a nested structure:\n",
    "- `STU00001/` - Patient study directory\n",
    "- `SER00001/`, `SER00002/`, ... - Series directories (different MRI sequences)\n",
    "- `0.npy`, `1.npy`, ... - Individual 2D slice files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports\n",
    "Let's start by importing the necessary DALI modules and NumPy for data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali as dali\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CLAHE Pipeline\n",
    "The main pipeline function creates a DALI processing pipeline that applies CLAHE enhancement to images. This pipeline can work with either real images from a directory or synthetic test data.\n",
    "\n",
    "**Key CLAHE Parameters:**\n",
    "- `tiles_x`, `tiles_y`: Grid size for local processing (higher = more local adaptation)\n",
    "- `clip_limit`: Threshold to prevent noise amplification (higher = more contrast)\n",
    "- `luma_only`: For RGB: process only luminance channel (preserves color balance)\n",
    "\n",
    "> **Try it yourself:** Review the function below and see how you can adjust the parameters for your own images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clahe_pipeline(\n",
    "    batch_size=4, num_threads=2, device_id=0, image_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DALI pipeline with CLAHE operator.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Number of images per batch\n",
    "        num_threads (int): Number of worker threads\n",
    "        device_id (int): GPU device ID\n",
    "        image_dir (str): Directory containing images (if None, uses synthetic data)\n",
    "\n",
    "    Returns:\n",
    "        DALI pipeline with CLAHE preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    @dali.pipeline_def(\n",
    "        batch_size=batch_size, num_threads=num_threads, device_id=device_id\n",
    "    )\n",
    "    def clahe_preprocessing_pipeline():\n",
    "        if image_dir:\n",
    "            # Read images from directory\n",
    "            images, labels = fn.readers.file(\n",
    "                file_root=image_dir, random_shuffle=True\n",
    "            )\n",
    "            images = fn.decoders.image(images, device=\"mixed\")  # Decode on GPU\n",
    "\n",
    "            # Resize to consistent size\n",
    "            images = fn.resize(images, size=[256, 256])\n",
    "        else:\n",
    "            # Create synthetic test images with varying contrast\n",
    "            # This simulates real-world scenarios where CLAHE is beneficial\n",
    "\n",
    "            # Generate base image with moderate values to avoid overflow\n",
    "            images = fn.random.uniform(\n",
    "                range=(60, 180), shape=(256, 256, 3), dtype=types.FLOAT\n",
    "            )\n",
    "\n",
    "            # Add some contrast variation to make CLAHE effect visible\n",
    "            contrast_factor = fn.random.uniform(range=(0.5, 0.9))\n",
    "            images = images * contrast_factor\n",
    "\n",
    "            # Add small brightness variation (keeping within safe range)\n",
    "            brightness_offset = fn.random.uniform(range=(-20, 20))\n",
    "            images = images + brightness_offset\n",
    "\n",
    "            # Convert to uint8 (DALI will automatically clamp to [0,255])\n",
    "            images = fn.cast(images, dtype=types.UINT8)\n",
    "\n",
    "        # ðŸŽ¯ Apply CLAHE for adaptive histogram equalization\n",
    "        # This is where the magic happens!\n",
    "        clahe_images = fn.clahe(\n",
    "            images,\n",
    "            tiles_x=8,  # 8x8 grid of tiles for local processing\n",
    "            tiles_y=8,\n",
    "            clip_limit=2.0,  # Moderate clipping to prevent noise\n",
    "            luma_only=True,  # RGB: process luminance only to preserve colors\n",
    "        )\n",
    "\n",
    "        return images, clahe_images\n",
    "\n",
    "    return clahe_preprocessing_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Comparison Function\n",
    "Let's create a function to demonstrate how different CLAHE parameters affect the results.\n",
    "\n",
    "> **Try it yourself:** Experiment with different values for `tiles_x`, `tiles_y`, and `clip_limit` to see their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clahe_parameters():\n",
    "    \"\"\"\n",
    "    Demonstrate different CLAHE parameter settings to show their effects.\n",
    "\n",
    "    Returns:\n",
    "        DALI pipeline that generates one base image and three CLAHE variants\n",
    "    \"\"\"\n",
    "\n",
    "    @dali.pipeline_def(batch_size=1, num_threads=1, device_id=0)\n",
    "    def parameter_demo_pipeline():\n",
    "        # Create a test image with poor contrast (narrow intensity range)\n",
    "        base_image = fn.random.uniform(\n",
    "            range=(80, 120), shape=(256, 256, 1), dtype=types.UINT8\n",
    "        )\n",
    "\n",
    "        # ðŸ”§ Different CLAHE configurations to compare:\n",
    "\n",
    "        # 1. Default settings - balanced approach\n",
    "        clahe_default = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=8,\n",
    "            tiles_y=8,  # Standard 8x8 grid\n",
    "            clip_limit=2.0,  # Moderate contrast limiting\n",
    "        )\n",
    "\n",
    "        # 2. Aggressive enhancement - more contrast, more local adaptation\n",
    "        clahe_aggressive = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=16,\n",
    "            tiles_y=16,  # Finer 16x16 grid\n",
    "            clip_limit=4.0,  # Higher contrast limit\n",
    "        )\n",
    "\n",
    "        # 3. Gentle enhancement - subtle improvement\n",
    "        clahe_gentle = fn.clahe(\n",
    "            base_image,\n",
    "            tiles_x=4,\n",
    "            tiles_y=4,  # Coarser 4x4 grid\n",
    "            clip_limit=1.0,  # Conservative contrast limit\n",
    "        )\n",
    "\n",
    "        return base_image, clahe_default, clahe_aggressive, clahe_gentle\n",
    "\n",
    "    return parameter_demo_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the CLAHE Pipeline\n",
    "Now let's execute our pipeline and see CLAHE in action! We'll analyze the results and measure the contrast improvement.\n",
    "\n",
    "> **Try it yourself:** Run the next cell and observe the printed analysis for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLAHE pipeline...\n",
      "Pipeline built successfully\n",
      "\n",
      "Running pipeline...\n",
      "Processed 2 images\n",
      "\n",
      "==================================================\n",
      "CLAHE RESULTS ANALYSIS\n",
      "==================================================\n",
      "\n",
      "  Image 1:\n",
      "  Original  - Shape: (256, 256, 3), Range: [57.0, 142.0]\n",
      "  Enhanced  - Shape: (256, 256, 3), Range: [15.0, 221.0]\n",
      "  Contrast improvement: 1.83x\n",
      "\n",
      "  Image 2:\n",
      "  Original  - Shape: (256, 256, 3), Range: [57.0, 156.0]\n",
      "  Enhanced  - Shape: (256, 256, 3), Range: [0.0, 236.0]\n",
      "  Contrast improvement: 1.76x\n",
      "\n",
      "CLAHE pipeline executed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create and build pipeline\n",
    "print(\"Creating CLAHE pipeline...\")\n",
    "pipe = create_clahe_pipeline(batch_size=2, num_threads=1, device_id=0)\n",
    "pipe.build()\n",
    "print(\"Pipeline built successfully\")\n",
    "\n",
    "# Run pipeline\n",
    "print(\"\\nRunning pipeline...\")\n",
    "outputs = pipe.run()\n",
    "original_images, clahe_images = outputs\n",
    "\n",
    "# Move to CPU for analysis\n",
    "original_batch = original_images.as_cpu()\n",
    "clahe_batch = clahe_images.as_cpu()\n",
    "\n",
    "print(f\"Processed {len(original_batch)} images\")\n",
    "\n",
    "# Analyze results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CLAHE RESULTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(len(original_batch)):\n",
    "    original = np.array(original_batch[i])\n",
    "    enhanced = np.array(clahe_batch[i])\n",
    "\n",
    "    print(f\"\\n  Image {i + 1}:\")\n",
    "    print(\n",
    "        f\"  Original  - Shape: {original.shape}, Range: [{original.min():.1f}, {original.max():.1f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Enhanced  - Shape: {enhanced.shape}, Range: [{enhanced.min():.1f}, {enhanced.max():.1f}]\"\n",
    "    )\n",
    "\n",
    "    # Calculate contrast metrics (standard deviation as a proxy for contrast)\n",
    "    orig_std = np.std(original)\n",
    "    enhanced_std = np.std(enhanced)\n",
    "    contrast_improvement = enhanced_std / orig_std if orig_std > 0 else 1.0\n",
    "\n",
    "    print(f\"  Contrast improvement: {contrast_improvement:.2f}x\")\n",
    "\n",
    "print(\"\\nCLAHE pipeline executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Comparison Experiment\n",
    "Let's compare different CLAHE parameter settings to understand their effects on image enhancement.\n",
    "\n",
    "> **Try it yourself:** Run the cell below and compare the standard deviation values for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate parameter variations\n",
    "print(\"Testing different CLAHE parameters...\")\n",
    "param_pipe = demonstrate_clahe_parameters()\n",
    "param_pipe.build()\n",
    "\n",
    "param_outputs = param_pipe.run()\n",
    "base, default, aggressive, gentle = param_outputs\n",
    "\n",
    "# Convert to numpy arrays for analysis\n",
    "base_img = np.array(base.as_cpu()[0])\n",
    "default_img = np.array(default.as_cpu()[0])\n",
    "aggressive_img = np.array(aggressive.as_cpu()[0])\n",
    "gentle_img = np.array(gentle.as_cpu()[0])\n",
    "\n",
    "# Compare the results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PARAMETER COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configurations = [\n",
    "    (\"Base image (no CLAHE)\", base_img),\n",
    "    (\"Default CLAHE (8x8, limit=2.0)\", default_img),\n",
    "    (\"Aggressive CLAHE (16x16, limit=4.0)\", aggressive_img),\n",
    "    (\"Gentle CLAHE (4x4, limit=1.0)\", gentle_img),\n",
    "]\n",
    "\n",
    "for name, img in configurations:\n",
    "    std_dev = np.std(img)\n",
    "    print(f\"{name}\")\n",
    "    print(f\"   Standard deviation (contrast measure): {std_dev:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\" Key Takeaways:\")\n",
    "print(\"   â€¢ Higher std dev = more contrast\")\n",
    "print(\"   â€¢ More tiles (16x16) = more local adaptation\")\n",
    "print(\"   â€¢ Higher clip limit = stronger enhancement\")\n",
    "print(\"   â€¢ Choose parameters based on your image type and requirements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Applications & Next Steps\n",
    "Where can you use CLAHE?\n",
    "- ðŸ¥ **Medical Imaging** (Best use case): Enhance X-rays, CT scans, MRI images\n",
    "  - Reveals subtle tissue boundaries and pathological structures\n",
    "  - Improves diagnostic visualization without changing underlying data\n",
    "  - Essential for low-contrast modalities like MRI and ultrasound\n",
    "- ðŸ‘ï¸ **Computer Vision**: Improve object detection in low-contrast scenes\n",
    "- ðŸ“¸ **Photography**: Enhance details in shadows and highlights\n",
    "- ðŸ›¡ï¸ **Security**: Improve visibility in surveillance footage\n",
    "- ðŸŒŒ **Astronomy**: Enhance celestial object visibility\n",
    "- ðŸ”¬ **Microscopy**: Reveal cellular structures in biological samples\n",
    "\n",
    "**Parameter Tuning Guidelines:**\n",
    "- **Medical scans (MRI, CT)**: tiles_x/y = 8-12, clip_limit = 2.0-3.5\n",
    "  - Higher clip_limit for very low-contrast tissue boundaries\n",
    "  - Moderate tile size to preserve spatial relationships\n",
    "- **X-rays**: tiles_x/y = 6-10, clip_limit = 2.0-3.0\n",
    "- **Natural photos**: tiles_x/y = 6-10, clip_limit = 2.0-3.0\n",
    "- **Low-light images**: tiles_x/y = 10-16, clip_limit = 3.0-4.0\n",
    "- **High-noise images**: tiles_x/y = 4-8, clip_limit = 1.0-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DALI CLAHE vs OpenCV CLAHE on Medical Imaging (Knee MRI)\n",
    "This section demonstrates CLAHE on **real low-contrast medical imaging data** - knee MRI slices from the DALI_extra repository. Medical imaging is where CLAHE truly shines, as these images often have naturally low contrast that benefits significantly from adaptive histogram equalization.\n",
    "\n",
    "The knee MRI slices (`db/3D/MRI/Knee/npy_2d_slices/STU00001/SER00001/`) are perfect for demonstrating CLAHE because:\n",
    "- **Low local contrast**: MRI data typically has subtle tissue boundaries\n",
    "- **Grayscale**: Single-channel data ideal for CLAHE\n",
    "- **Real-world clinical data**: Demonstrates practical medical imaging applications\n",
    "- **Multiple sequences**: 15 different series (SER00001-SER00015) available for experimentation\n",
    "\n",
    "> **Try it yourself:** Run the next cells to see side-by-side results on actual medical imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: Load knee MRI slice from DALI_extra ---\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to DALI_extra MRI data\n",
    "# The DALI_EXTRA_PATH should point to your DALI_extra repository\n",
    "dali_extra_path = os.environ.get('DALI_EXTRA_PATH')\n",
    "\n",
    "if dali_extra_path and os.path.exists(dali_extra_path):\n",
    "    # Path to knee MRI 2D slices (nested in STU00001/SER00001/ subdirectories)\n",
    "    mri_base_path = os.path.join(dali_extra_path, 'db/3D/MRI/Knee/npy_2d_slices')\n",
    "    \n",
    "    if os.path.exists(mri_base_path):\n",
    "        # Find .npy files in nested subdirectories (e.g., STU00001/SER00001/*.npy)\n",
    "        npy_pattern = os.path.join(mri_base_path, 'STU00001/SER00001/*.npy')\n",
    "        npy_files = sorted(glob.glob(npy_pattern))\n",
    "        \n",
    "        if npy_files:\n",
    "            print(f\"Loading knee MRI slice from DALI_extra...\")\n",
    "            print(f\"Found {len(npy_files)} MRI slices in STU00001/SER00001/\")\n",
    "            \n",
    "            # Load the first MRI slice (or you can choose a different index)\n",
    "            mri_data = np.load(npy_files[0])\n",
    "            \n",
    "            print(f\"MRI slice loaded: {os.path.basename(npy_files[0])}\")\n",
    "            print(f\"Original shape: {mri_data.shape}, dtype: {mri_data.dtype}\")\n",
    "            \n",
    "            # Normalize to uint8 if needed\n",
    "            if mri_data.dtype != np.uint8:\n",
    "                # Normalize to 0-255 range\n",
    "                mri_min, mri_max = mri_data.min(), mri_data.max()\n",
    "                if mri_max > mri_min:\n",
    "                    mri_data = ((mri_data - mri_min) / (mri_max - mri_min) * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    mri_data = np.zeros_like(mri_data, dtype=np.uint8)\n",
    "                print(f\"Normalized to uint8: range [{mri_data.min()}, {mri_data.max()}]\")\n",
    "            \n",
    "            # Ensure it has channel dimension (H, W, 1) for DALI compatibility\n",
    "            if len(mri_data.shape) == 2:\n",
    "                image = np.expand_dims(mri_data, axis=-1)\n",
    "            else:\n",
    "                image = mri_data\n",
    "            \n",
    "            print(f\"Final shape for processing: {image.shape}\")\n",
    "            \n",
    "            # Display the original MRI slice\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(image.squeeze(), cmap='gray', vmin=0, vmax=255)\n",
    "            plt.title(f\"Original Knee MRI Slice: {os.path.basename(npy_files[0])}\")\n",
    "            plt.colorbar(label='Intensity')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nNote: Notice the low contrast in this medical image - perfect for CLAHE.\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error: No .npy files found in {npy_pattern}\")\n",
    "            raise FileNotFoundError(f\"No MRI data found at {npy_pattern}\")\n",
    "    else:\n",
    "        print(f\"Error: MRI base path not found: {mri_base_path}\")\n",
    "        raise FileNotFoundError(f\"MRI base path not found: {mri_base_path}\")\n",
    "else:\n",
    "    print(\"Error: DALI_EXTRA_PATH environment variable not set or path doesn't exist\")\n",
    "    print(\"Please set it to your DALI_extra repository path:\")\n",
    "    print(\"export DALI_EXTRA_PATH=/path/to/DALI_extra\")\n",
    "    raise EnvironmentError(\"DALI_EXTRA_PATH not properly configured\")\n",
    "\n",
    "print(f\"\\nImage statistics:\")\n",
    "print(f\"Mean: {image.mean():.1f}, Std: {image.std():.1f}\")\n",
    "print(f\"Min: {image.min()}, Max: {image.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CLAHE Processing: OpenCV and DALI ---\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def apply_opencv_clahe(\n",
    "    image, tiles_x=8, tiles_y=8, clip_limit=2.0, luma_only=True\n",
    "):\n",
    "    clahe = cv2.createCLAHE(\n",
    "        clipLimit=float(clip_limit), tileGridSize=(tiles_x, tiles_y)\n",
    "    )\n",
    "\n",
    "    # Handle grayscale images (shape: H x W x 1 or H x W)\n",
    "    if len(image.shape) == 2 or (len(image.shape) == 3 and image.shape[2] == 1):\n",
    "        # For grayscale, just apply CLAHE directly\n",
    "        img_2d = image.squeeze() if len(image.shape) == 3 else image\n",
    "        result = clahe.apply(img_2d)\n",
    "        # Return with same shape as input\n",
    "        if len(image.shape) == 3:\n",
    "            result = np.expand_dims(result, axis=-1)\n",
    "    # Handle RGB images (shape: H x W x 3)\n",
    "    elif len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        if luma_only:\n",
    "            lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "            lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "            result = cv2.cvtColor(lab, cv2.COLOR_Lab2RGB)\n",
    "        else:\n",
    "            result = np.zeros_like(image)\n",
    "            for i in range(3):\n",
    "                result[:, :, i] = clahe.apply(image[:, :, i])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image shape: {image.shape}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class MemoryPipeline(Pipeline):\n",
    "    def __init__(\n",
    "        self, image_array, tiles_x=8, tiles_y=8, clip_limit=2.0, device=\"gpu\"\n",
    "    ):\n",
    "        super().__init__(batch_size=1, num_threads=1, device_id=0)\n",
    "        self.image_array = image_array\n",
    "        self.tiles_x = tiles_x\n",
    "        self.tiles_y = tiles_y\n",
    "        self.clip_limit = clip_limit\n",
    "        self.device = device\n",
    "\n",
    "    def define_graph(self):\n",
    "        images = fn.external_source(\n",
    "            source=lambda: [self.image_array],\n",
    "            device=\"cpu\",\n",
    "            dtype=types.DALIDataType.UINT8,\n",
    "            ndim=3,\n",
    "        )\n",
    "        if self.device == \"gpu\":\n",
    "            images_processed = images.gpu()\n",
    "        else:\n",
    "            images_processed = images\n",
    "        clahe_result = fn.clahe(\n",
    "            images_processed,\n",
    "            tiles_x=self.tiles_x,\n",
    "            tiles_y=self.tiles_y,\n",
    "            clip_limit=float(self.clip_limit),\n",
    "            luma_only=False,  # For grayscale, luma_only should be False\n",
    "            device=self.device,\n",
    "        )\n",
    "        return clahe_result\n",
    "\n",
    "\n",
    "# Parameters\n",
    "tiles_x, tiles_y, clip_limit = 8, 8, 2.0\n",
    "\n",
    "# OpenCV CLAHE\n",
    "opencv_result = apply_opencv_clahe(image, tiles_x, tiles_y, clip_limit)\n",
    "\n",
    "# DALI CLAHE GPU\n",
    "pipe_gpu = MemoryPipeline(image, tiles_x, tiles_y, clip_limit, \"gpu\")\n",
    "pipe_gpu.build()\n",
    "dali_gpu_result = pipe_gpu.run()[0].as_cpu().as_array()[0]\n",
    "\n",
    "# DALI CLAHE CPU\n",
    "pipe_cpu = MemoryPipeline(image, tiles_x, tiles_y, clip_limit, \"cpu\")\n",
    "pipe_cpu.build()\n",
    "dali_cpu_result = pipe_cpu.run()[0].as_cpu().as_array()[0]\n",
    "\n",
    "# Calculate MSE and MAE between implementations\n",
    "def calculate_metrics(img1, img2):\n",
    "    \"\"\"Calculate MSE and MAE between two images.\"\"\"\n",
    "    mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
    "    mae = np.mean(np.abs(img1.astype(float) - img2.astype(float)))\n",
    "    return mse, mae\n",
    "\n",
    "# Flatten images for comparison\n",
    "opencv_flat = opencv_result.squeeze()\n",
    "dali_gpu_flat = dali_gpu_result.squeeze()\n",
    "dali_cpu_flat = dali_cpu_result.squeeze()\n",
    "\n",
    "# Calculate metrics\n",
    "mse_ocv_gpu, mae_ocv_gpu = calculate_metrics(opencv_flat, dali_gpu_flat)\n",
    "mse_ocv_cpu, mae_ocv_cpu = calculate_metrics(opencv_flat, dali_cpu_flat)\n",
    "mse_gpu_cpu, mae_gpu_cpu = calculate_metrics(dali_gpu_flat, dali_cpu_flat)\n",
    "\n",
    "# Show results\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axes[0].imshow(image.squeeze(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(opencv_result.squeeze(), cmap=\"gray\")\n",
    "axes[1].set_title(\"OpenCV CLAHE\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(dali_gpu_result.squeeze(), cmap=\"gray\")\n",
    "axes[2].set_title(\"DALI CLAHE (GPU)\")\n",
    "axes[2].axis(\"off\")\n",
    "axes[3].imshow(dali_cpu_result.squeeze(), cmap=\"gray\")\n",
    "axes[3].set_title(\"DALI CLAHE (CPU)\")\n",
    "axes[3].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Print comparison metrics\n",
    "print(\"\\nImplementation Comparison Metrics:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OpenCV vs DALI GPU:  MSE = {mse_ocv_gpu:.4f}, MAE = {mae_ocv_gpu:.4f}\")\n",
    "print(f\"OpenCV vs DALI CPU:  MSE = {mse_ocv_cpu:.4f}, MAE = {mae_ocv_cpu:.4f}\")\n",
    "print(f\"DALI GPU vs CPU:     MSE = {mse_gpu_cpu:.4f}, MAE = {mae_gpu_cpu:.4f}\")\n",
    "print(\"\\nNote: Lower values indicate closer agreement between implementations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Difference Maps and Luminance Histograms ---\n",
    "def get_luminance(img):\n",
    "    \"\"\"Extract luminance from image. For grayscale, just return the image.\"\"\"\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    elif len(img.shape) == 3 and img.shape[2] == 1:\n",
    "        return img.squeeze()\n",
    "    else:\n",
    "        # For RGB images, convert to YUV and extract Y channel\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)[:, :, 0]\n",
    "\n",
    "\n",
    "# Calculate differences\n",
    "diff_opencv_dali_gpu = np.abs(\n",
    "    opencv_result.astype(float) - dali_gpu_result.astype(float)\n",
    ")\n",
    "diff_opencv_dali_cpu = np.abs(\n",
    "    opencv_result.astype(float) - dali_cpu_result.astype(float)\n",
    ")\n",
    "diff_dali_gpu_cpu = np.abs(\n",
    "    dali_gpu_result.astype(float) - dali_cpu_result.astype(float)\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Top row: images\n",
    "axes[0, 0].imshow(image.squeeze(), cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Original\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "axes[0, 1].imshow(opencv_result.squeeze(), cmap=\"gray\")\n",
    "axes[0, 1].set_title(\"OpenCV CLAHE\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "axes[0, 2].imshow(dali_gpu_result.squeeze(), cmap=\"gray\")\n",
    "axes[0, 2].set_title(\"DALI CLAHE (GPU)\")\n",
    "axes[0, 2].axis(\"off\")\n",
    "axes[0, 3].imshow(dali_cpu_result.squeeze(), cmap=\"gray\")\n",
    "axes[0, 3].set_title(\"DALI CLAHE (CPU)\")\n",
    "axes[0, 3].axis(\"off\")\n",
    "\n",
    "# Bottom row: difference maps\n",
    "# For grayscale images, no need to average across channels\n",
    "diff_opencv_gpu_2d = diff_opencv_dali_gpu.squeeze()\n",
    "diff_opencv_cpu_2d = diff_opencv_dali_cpu.squeeze()\n",
    "diff_gpu_cpu_2d = diff_dali_gpu_cpu.squeeze()\n",
    "\n",
    "axes[1, 0].imshow(diff_opencv_gpu_2d, cmap=\"hot\", vmin=0, vmax=50)\n",
    "axes[1, 0].set_title(\"Diff (OpenCV - DALI GPU)\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "axes[1, 1].imshow(diff_opencv_cpu_2d, cmap=\"hot\", vmin=0, vmax=50)\n",
    "axes[1, 1].set_title(\"Diff (OpenCV - DALI CPU)\")\n",
    "axes[1, 1].axis(\"off\")\n",
    "axes[1, 2].imshow(diff_gpu_cpu_2d, cmap=\"hot\", vmin=0, vmax=50)\n",
    "axes[1, 2].set_title(\"Diff (DALI GPU - CPU)\")\n",
    "axes[1, 2].axis(\"off\")\n",
    "\n",
    "# Intensity histograms\n",
    "orig_lum = get_luminance(image)\n",
    "opencv_lum = get_luminance(opencv_result)\n",
    "dali_gpu_lum = get_luminance(dali_gpu_result)\n",
    "\n",
    "axes[1, 3].hist(\n",
    "    orig_lum.ravel(), bins=50, alpha=0.5, color=\"gray\", label=\"Original\"\n",
    ")\n",
    "axes[1, 3].hist(\n",
    "    opencv_lum.ravel(), bins=50, alpha=0.7, color=\"blue\", label=\"OpenCV\"\n",
    ")\n",
    "axes[1, 3].hist(\n",
    "    dali_gpu_lum.ravel(), bins=50, alpha=0.7, color=\"red\", label=\"DALI GPU\"\n",
    ")\n",
    "axes[1, 3].set_title(\"Intensity Histograms\")\n",
    "axes[1, 3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing MRI Slices with DALI Numpy Reader\n",
    "Let's demonstrate a more realistic medical imaging workflow: processing **multiple MRI slices in batch** using DALI's numpy reader. This showcases DALI's strength in efficient data loading and GPU-accelerated processing.\n",
    "\n",
    "> **Try it yourself:** This cell processes multiple MRI slices simultaneously, demonstrating the power of batched CLAHE processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Batch MRI Processing with DALI Numpy Reader ---\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "\n",
    "def create_mri_clahe_pipeline(mri_data_path, batch_size=4, tiles_x=8, tiles_y=8, clip_limit=2.0):\n",
    "    \"\"\"\n",
    "    Create a DALI pipeline that reads MRI .npy files and applies CLAHE.\n",
    "    \n",
    "    Args:\n",
    "        mri_data_path: Path to directory containing .npy files\n",
    "        batch_size: Number of slices to process per batch\n",
    "        tiles_x, tiles_y: CLAHE tile grid parameters\n",
    "        clip_limit: CLAHE contrast limiting parameter\n",
    "    \n",
    "    Returns:\n",
    "        DALI pipeline for batch MRI processing\n",
    "    \"\"\"\n",
    "    \n",
    "    @dali.pipeline_def(batch_size=batch_size, num_threads=2, device_id=0)\n",
    "    def mri_processing_pipeline():\n",
    "        # Read .npy files using DALI's numpy reader\n",
    "        # This efficiently loads numpy arrays directly into DALI pipeline\n",
    "        mri_slices = fn.readers.numpy(\n",
    "            file_root=mri_data_path,\n",
    "            file_filter=\"*.npy\",\n",
    "            device=\"cpu\",\n",
    "            random_shuffle=False,\n",
    "            pad_last_batch=True\n",
    "        )\n",
    "        \n",
    "        # Normalize to uint8 if needed (most MRI data comes as float)\n",
    "        # Check data type and normalize to 0-255 range\n",
    "        mri_slices = fn.cast(mri_slices, dtype=types.FLOAT)\n",
    "        \n",
    "        # Normalize to [0, 1] range first\n",
    "        min_val = fn.reductions.min(mri_slices)\n",
    "        max_val = fn.reductions.max(mri_slices)\n",
    "        mri_normalized = (mri_slices - min_val) / (max_val - min_val + 1e-8)\n",
    "        \n",
    "        # Scale to [0, 255] and convert to uint8\n",
    "        mri_uint8 = fn.cast(mri_normalized * 255, dtype=types.UINT8)\n",
    "        \n",
    "        # Add channel dimension to make it HWC format (required by CLAHE)\n",
    "        # For 2D data (H, W), add axis at position 2 to get (H, W, 1)\n",
    "        # First assign HW layout, then expand to add channel dimension\n",
    "        mri_uint8 = fn.reshape(mri_uint8, layout=\"HW\")\n",
    "        mri_uint8 = fn.expand_dims(mri_uint8, axes=2, new_axis_names=\"C\")\n",
    "        \n",
    "        # Move to GPU for CLAHE processing\n",
    "        mri_gpu = mri_uint8.gpu()\n",
    "        \n",
    "        # Apply CLAHE on GPU\n",
    "        clahe_output = fn.clahe(\n",
    "            mri_gpu,\n",
    "            tiles_x=tiles_x,\n",
    "            tiles_y=tiles_y,\n",
    "            clip_limit=clip_limit,\n",
    "            luma_only=False  # For grayscale, luma_only should be False\n",
    "        )\n",
    "        \n",
    "        return mri_uint8, clahe_output\n",
    "    \n",
    "    return mri_processing_pipeline()\n",
    "\n",
    "\n",
    "# Check if we have MRI data available\n",
    "dali_extra_path = os.environ.get('DALI_EXTRA_PATH')\n",
    "\n",
    "if dali_extra_path and os.path.exists(dali_extra_path):\n",
    "    # MRI data is in nested subdirectories: STU00001/SER00001/*.npy\n",
    "    mri_path = os.path.join(dali_extra_path, 'db/3D/MRI/Knee/npy_2d_slices/STU00001/SER00001')\n",
    "    \n",
    "    if os.path.exists(mri_path):\n",
    "        npy_files = glob.glob(os.path.join(mri_path, '*.npy'))\n",
    "        \n",
    "        if len(npy_files) >= 4:\n",
    "            print(f\"Processing knee MRI slices with DALI...\")\n",
    "            print(f\"Found {len(npy_files)} slices in STU00001/SER00001/\")\n",
    "            print(f\"Path: {mri_path}\")\n",
    "            \n",
    "            # Create and build pipeline\n",
    "            batch_size = min(4, len(npy_files))\n",
    "            mri_pipe = create_mri_clahe_pipeline(\n",
    "                mri_data_path=mri_path,\n",
    "                batch_size=batch_size,\n",
    "                tiles_x=8,\n",
    "                tiles_y=8,\n",
    "                clip_limit=3.0  # Higher clip limit for medical imaging\n",
    "            )\n",
    "            mri_pipe.build()\n",
    "            \n",
    "            # Run pipeline\n",
    "            print(f\"\\nRunning batch CLAHE on {batch_size} MRI slices...\")\n",
    "            outputs = mri_pipe.run()\n",
    "            original_batch, clahe_batch = outputs\n",
    "            \n",
    "            # Convert to numpy for visualization\n",
    "            original_np = [np.array(original_batch[i].as_cpu()).squeeze() for i in range(batch_size)]\n",
    "            clahe_np = [np.array(clahe_batch[i].as_cpu()).squeeze() for i in range(batch_size)]\n",
    "            \n",
    "            # Visualize results in a grid\n",
    "            fig, axes = plt.subplots(2, batch_size, figsize=(20, 10))\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                # Original MRI\n",
    "                axes[0, i].imshow(original_np[i], cmap='gray', vmin=0, vmax=255)\n",
    "                axes[0, i].set_title(f'Original Slice {i+1}')\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                # CLAHE enhanced MRI\n",
    "                axes[1, i].imshow(clahe_np[i], cmap='gray', vmin=0, vmax=255)\n",
    "                axes[1, i].set_title(f'CLAHE Enhanced {i+1}')\n",
    "                axes[1, i].axis('off')\n",
    "            \n",
    "            plt.suptitle('Batch MRI Processing: Original vs CLAHE Enhanced', fontsize=16, y=0.98)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Compute contrast improvement statistics\n",
    "            print(\"\\nContrast Improvement Analysis:\")\n",
    "            print(\"=\" * 60)\n",
    "            for i in range(batch_size):\n",
    "                orig_std = np.std(original_np[i])\n",
    "                clahe_std = np.std(clahe_np[i])\n",
    "                improvement = clahe_std / orig_std if orig_std > 0 else 1.0\n",
    "                \n",
    "                print(f\"Slice {i+1}:\")\n",
    "                print(f\"  Original - Mean: {original_np[i].mean():.1f}, Std: {orig_std:.1f}\")\n",
    "                print(f\"  Enhanced - Mean: {clahe_np[i].mean():.1f}, Std: {clahe_std:.1f}\")\n",
    "                print(f\"  Contrast improvement: {improvement:.2f}x\")\n",
    "                print()\n",
    "            \n",
    "            print(\"Batch processing complete!\")\n",
    "            print(\"Note: CLAHE reveals subtle tissue structures in the MRI slices.\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Warning: Not enough MRI files found ({len(npy_files)} < 4)\")\n",
    "            print(\"Need at least 4 files for batch demonstration\")\n",
    "    else:\n",
    "        print(f\"Warning: MRI path not found: {mri_path}\")\n",
    "        print(\"Expected path: $DALI_EXTRA_PATH/db/3D/MRI/Knee/npy_2d_slices/STU00001/SER00001/\")\n",
    "else:\n",
    "    print(\"Warning: DALI_EXTRA_PATH not set or invalid\")\n",
    "    print(\"To use this feature, set the environment variable:\")\n",
    "    print(\"export DALI_EXTRA_PATH=/path/to/DALI_extra\")\n",
    "    print(\"\\nThe knee MRI data should be at:\")\n",
    "    print(\"$DALI_EXTRA_PATH/db/3D/MRI/Knee/npy_2d_slices/STU00001/SER00001/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding CLAHE's Effect on Medical Images\n",
    "Let's analyze how CLAHE transforms the intensity distribution of MRI data, which helps understand why it's so effective for medical imaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram Analysis for Medical Imaging ---\n",
    "\n",
    "# Check if we have MRI results from previous cell\n",
    "if 'original_np' in locals() and 'clahe_np' in locals() and len(original_np) > 0:\n",
    "    # Analyze the first slice in detail\n",
    "    orig_slice = original_np[0]\n",
    "    clahe_slice = clahe_np[0]\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Images\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    im1 = ax1.imshow(orig_slice, cmap='gray', vmin=0, vmax=255)\n",
    "    ax1.set_title('Original MRI Slice', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    im2 = ax2.imshow(clahe_slice, cmap='gray', vmin=0, vmax=255)\n",
    "    ax2.set_title('CLAHE Enhanced', fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    diff = np.abs(clahe_slice.astype(float) - orig_slice.astype(float))\n",
    "    im3 = ax3.imshow(diff, cmap='hot', vmin=0, vmax=100)\n",
    "    ax3.set_title('Absolute Difference', fontsize=14, fontweight='bold')\n",
    "    ax3.axis('off')\n",
    "    plt.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04, label='Intensity Change')\n",
    "    \n",
    "    # Row 2: Histograms\n",
    "    ax4 = fig.add_subplot(gs[1, :])\n",
    "    ax4.hist(orig_slice.ravel(), bins=256, alpha=0.6, color='blue', \n",
    "             label='Original', range=(0, 255), density=True)\n",
    "    ax4.hist(clahe_slice.ravel(), bins=256, alpha=0.6, color='red', \n",
    "             label='CLAHE Enhanced', range=(0, 255), density=True)\n",
    "    ax4.set_xlabel('Pixel Intensity', fontsize=12)\n",
    "    ax4.set_ylabel('Normalized Frequency', fontsize=12)\n",
    "    ax4.set_title('Intensity Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(fontsize=11)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 3: Statistics\n",
    "    ax5 = fig.add_subplot(gs[2, :])\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    # Calculate statistics\n",
    "    orig_mean = orig_slice.mean()\n",
    "    orig_std = orig_slice.std()\n",
    "    orig_min = orig_slice.min()\n",
    "    orig_max = orig_slice.max()\n",
    "    \n",
    "    clahe_mean = clahe_slice.mean()\n",
    "    clahe_std = clahe_slice.std()\n",
    "    clahe_min = clahe_slice.min()\n",
    "    clahe_max = clahe_slice.max()\n",
    "    \n",
    "    # Calculate entropy (measure of information content)\n",
    "    orig_hist, _ = np.histogram(orig_slice.ravel(), bins=256, range=(0, 255), density=True)\n",
    "    clahe_hist, _ = np.histogram(clahe_slice.ravel(), bins=256, range=(0, 255), density=True)\n",
    "    \n",
    "    orig_entropy = -np.sum(orig_hist * np.log2(orig_hist + 1e-10))\n",
    "    clahe_entropy = -np.sum(clahe_hist * np.log2(clahe_hist + 1e-10))\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    QUANTITATIVE ANALYSIS:\n",
    "    \n",
    "    Original MRI:                          CLAHE Enhanced:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Mean:       {orig_mean:6.2f}                          Mean:       {clahe_mean:6.2f}\n",
    "    Std Dev:    {orig_std:6.2f}                          Std Dev:    {clahe_std:6.2f}\n",
    "    Min:        {orig_min:6.0f}                            Min:        {clahe_min:6.0f}\n",
    "    Max:        {orig_max:6.0f}                            Max:        {clahe_max:6.0f}\n",
    "    Entropy:    {orig_entropy:6.2f} bits                   Entropy:    {clahe_entropy:6.2f} bits\n",
    "    \n",
    "    IMPROVEMENTS:\n",
    "    â€¢ Contrast increase: {(clahe_std/orig_std):.2f}x (measured by std dev ratio)\n",
    "    â€¢ Dynamic range: {orig_max-orig_min:.0f} â†’ {clahe_max-clahe_min:.0f} (fuller use of intensity range)\n",
    "    â€¢ Information content: {(clahe_entropy/orig_entropy):.2f}x (entropy ratio - more distinguishable features)\n",
    "    \n",
    "    INTERPRETATION:\n",
    "    â€¢ Higher std dev = better contrast and tissue differentiation\n",
    "    â€¢ Higher entropy = more information-rich image with better feature visibility\n",
    "    â€¢ CLAHE reveals subtle boundaries that were barely visible in the original\n",
    "    \"\"\"\n",
    "    \n",
    "    ax5.text(0.05, 0.95, stats_text, transform=ax5.transAxes,\n",
    "             fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.suptitle('Medical Image Analysis: CLAHE Enhancement Effect on MRI', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Analysis complete!\")\n",
    "    print(\"\\nKey Insight for Medical Imaging:\")\n",
    "    print(\"   CLAHE adaptively enhances local contrast in each tissue region,\")\n",
    "    print(\"   making it ideal for MRI where different tissues have overlapping\")\n",
    "    print(\"   intensity ranges but important local boundaries.\")\n",
    "    \n",
    "elif 'image' in locals():\n",
    "    # Fall back to single-image analysis from section 8\n",
    "    print(\"Analyzing single MRI slice from section 8...\")\n",
    "    \n",
    "    # Apply CLAHE to the single image for comparison\n",
    "    opencv_clahe = apply_opencv_clahe(image, tiles_x=8, tiles_y=8, clip_limit=3.0)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(image.squeeze(), cmap='gray', vmin=0, vmax=255)\n",
    "    axes[0].set_title('Original', fontsize=14)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(opencv_clahe.squeeze(), cmap='gray', vmin=0, vmax=255)\n",
    "    axes[1].set_title('CLAHE Enhanced', fontsize=14)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].hist(image.ravel(), bins=50, alpha=0.6, color='blue', label='Original')\n",
    "    axes[2].hist(opencv_clahe.ravel(), bins=50, alpha=0.6, color='red', label='CLAHE')\n",
    "    axes[2].set_title('Intensity Distributions', fontsize=14)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No MRI data available for histogram analysis\")\n",
    "    print(\"   Please run the previous cells to load MRI data first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

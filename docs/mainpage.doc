/**
 * @mainpage
 * 
 * @section intro Introduction
 * NDLL (Nvidia Data Loading Library) is broken into two mains parts. The first part
 * is a library of base primitives for data loading and augmentation. These are
 * organized in the source tree by what type of data they operate on. We currently
 * only have image primitives, so all of the primitives are located under @ref ndll/image/.
 *
 * The second part is a high performance data Pipeline (@ref ndll/pipeline). The pipeline 
 * is designed to be quite general and extensible.
 *
 * @section lib Library
 * The library is currently quite small, but the goal is to build up a set of primitives
 * used by the frameworks so that all frameworks have access to the same data augmentation
 * and data loading functions.
 *
 * @section pipe Pipeline
 * The Pipeline class is heavily documented. See @ref ndll::Pipeline for core docs, and 
 * the following classes for documentation on other important classes used in the Pipeline.
 *
 * @subsection ops Operators:
 * @ref ndll::Operator<Backend> @n
 * @ref ndll::Transformer<Backend> @n
 * @ref ndll::Decoder<Backend> @n
 * @ref ndll::DataReader @n
 * @ref ndll::Parser @n
 *
 * @subsection data Data Storage:
 * @ref ndll::Buffer<Backend> @n
 * @ref ndll::Batch<Backend> @n
 * @ref ndll::Tensor<Backend> @n
 * @ref ndll::Datum<Backend>
 *
 * @subsection mem Memory Allocation:
 * @ref ndll::CPUBackend @n
 * @ref ndll::GPUBackend @n
 * @ref ndll::AllocatorBase @n
 * @ref ndll::CPUAllocator @n
 * @ref ndll::GPUAllocator
 *
 * The Pipeline also has Python bindings that expose a very similar API to the C++
 * Pipeline. See the examples in 'ndll/benchmark'.
 *
 * @subsection pipe_struct Pipeline Structures:
 * @ref ndll::Channel
 *
 * @section todo TODO
 * This section discusses some areas where NDLL needs work.
 *
 * @subsection test Image Similarity Metrics
 * The BatchedResize methods currently fail in the test suite because they produce
 * images that are slightly off from the opencv resize method in terms of MSE, but
 * are identical when looking at them side by side. We should have better similarity
 * metrics in our test suite to fix this issue.
 *
 * @subsection include Including NDLL
 * I haven't decided on the best way to include NDLL. Currently we just include the
 * individual files we need, but this requires poking into the src tree which is
 * gross. Thinking about creating two header files: "ndll_lib.h" for the library
 * of primitives and "ndll_pipeline.h" for all pipeline stuff you need.
 *
 * @subsection inline Inline Member Functions
 * Alot of methods are defined inline in the pipeline. These should be moved out to
 * make the code more readable.
 *
 * @subsection docs Operator & Python Documentation
 * The only part of NDLL that isn't document well is the Operators. We need to figure
 * out a way to write docs for these that can then also be exposed to the Python API
 * as well. The Python API in general could use some more documentation.
 *
 * @subsection docker Docker Container Warning
 * In the C2+NDLL container, we get a warning "Unexpected end of /proc/mounts line..."
 * when we start up a run that uses the NDLL code. The internet seems to indicate this
 * could be produced by the hwloc library used by NVML. We should clean this up when
 * we get the chance.
 *
 * @subsection build Support Build for Different SMs
 * We currently don't have SM target options in the build for NDLL
 *
 * @subsection data NDLL Data Hierarchy
 * The hierarchy of classes used to store data in ndll is a bit complex, and some
 * resposibilities are redundant. We should refactor to remove the 'Datum' object
 * and replace them with Tensors. We can extend the Tensor class with a method
 * like 'ShareDataShard' to support the functionality that Datum objects provide.
 * We should also get rid of SubTensor and just use Tensor objects that wrap shards
 * of larger buffers. This could also likely be done with 'ShareDataShard'.
 *
 * @subsection c2 C2 Perf
 * C2+NDLL actually produces higher framerates than just NDLL. This is likely because
 * of different testing data, different data reader, or different parser, but I haven't
 * looked into which one it is exactly.
 */

/**
 * @mainpage
 * 
 * @section intro Introduction
 * NDLL (Nvidia Data Loading Library) is broken into two mains parts. The first part
 * is a library of base primitives for data loading and augmentation. These are
 * organized in the source tree by what type of data they operate on. We currently
 * only have image primitives, so all of the primitives are located under @ref ndll/image/.
 *
 * The second part is a high performance data Pipeline (@ref ndll/pipeline). The pipeline 
 * is designed to be quite general and extensible.
 *
 * @section lib Library
 * The library is currently quite small, but the goal is to build up a set of primitives
 * used by the frameworks so that all frameworks have access to the same data augmentation
 * and data loading functions.
 *
 * @section pipe Pipeline
 * The Pipeline class is heavily documented. See @ref ndll::Pipeline<CPUBackend, GPUBackend>
 * for core docs, and the following classes for documentation on other important classes used
 * in the Pipeline.
 *
 * @subsection ops Operators:
 * @ref ndll::Operator<Backend> @n
 * @ref ndll::Transformer<Backend> @n
 * @ref ndll::Decoder<Backend> @n
 * @ref ndll::DataReader<Backend, std::enable_if<std::is_base_of<CPUBackend, Backend>::value, int>::type> @n
 * @ref ndll::Parser<Backend, std::enable_if<std::is_base_of<CPUBackend, Backend>::value, int>::type>
 *
 * @subsection data Data Storage:
 * @ref ndll::Buffer<Backend> @n
 * @ref ndll::Batch<Backend> @n
 * @ref ndll::Tensor<Backend> @n
 * @ref ndll::Datum<Backend>
 *
 * @subsection mem Memory Allocation:
 * @ref ndll::BackendBase @n
 * @ref ndll::CPUBackend @n
 * @ref ndll::GPUBackend @n
 * @ref ndll::PinnedCPUBackend
 *
 *
 * @subsection pipe_struct Pipeline Structures:
 * @ref ndll::Channel
 *
 * @section design Design Strain
 * This section discusses some design points that are currently a bit strained and need
 * refactoring.
 *
 * @subsection template Template Backends
 * The use of a template parameter to specify the type of allocator in the Pipeline, 
 * Operators, and data storage classes is turning out to be a bit difficult. We use
 * template meta-programming to enforce requirements on backend data types, which is
 * a little hacky, and in cases where the user needs to have both types of allocators
 * (e.g., when defining an operator that works on both CPU & GPU) they need to have
 * a double template type. Double template is tricky because we use the template to
 * decide where the op can be executed, meaning that the ordering of the template
 * parameters when the op is constructed now determines where it is to be run. This
 * is gross and difficult to read. In the case of the Operator base class, I didn't
 * want to give it a double template for this reason, so I had to create sort-of hacky
 * {CPU, GPU}SubTensor objects to enable the batched paramter mega-buffer packing.
 *
 * The benefit of the template is that GPU & CPU data are different types. This is
 * quite nice as some errors using data located in the wrong place are converted 
 * into compiler errors that are easy to fix. If we didn't have a polymophic class
 * hierarchy for the Backends (to enable user defined allocators, which we need)
 * this wouldn't be an issue. However, template types are not polymorphic, and we
 * need some way of letting everyone use the user-defined allocators w/o needing
 * extra template types. I need to think about this issue more and figure out what
 * our exact requirements are.
 *
 * @subsection param Batch Size & Thread Pool Size
 * All ops need the batch size and thread pool size to set up whatever datum-wise
 * or thread local data they need. I didn't want users to have to pass this in to
 * every op, so I just set it in the pipeline and have the pipeline set it in all
 * the ops in the 'Pipeline::Build' method. This isn't great because the Ops can't
 * do some setup in their constructor, and they have to override the methods
 * that set these paramters to intialize their data. It also means we have to check
 * to make sure these have been set prior to doing stuff. I need to come up with a
 * better way to get this global information to everyone.
 *
 * @subsection inline Inline Member Functions
 * Alot of methods are defined inline in the pipeline. These should be moved out to
 * make the code more readable.
 */
